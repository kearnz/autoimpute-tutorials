{"version":3,"sources":["components/Contact.js","components/CodeBlock.js","components/Home.js","components/Comparing.js","components/ImputerI.js","components/ImputerII.js","components/ImputerIII.js","components/EndToEnd.js","components/Navigation.js","App.js","serviceWorker.js","index.js"],"names":["Contact","react_default","a","createElement","Component","CodeBlock","_this$props","this","props","language","value","default_highlight","style","docco","PureComponent","defaultProps","Home","react_markdown_default","source","escapeHtml","renderers","code","Comparing","className","border","alt","src","ImputerI","ImputerII","ImputerIII","EndToEnd","NavItem","pageURI","window","location","pathname","search","liClassName","path","aClassName","disabled","onClick","href","name","NavDropdown","_this","Object","classCallCheck","possibleConstructorReturn","getPrototypeOf","call","state","isToggleOn","e","preventDefault","setState","prevState","_this2","classDropdownMenu","id","role","data-toggle","aria-haspopup","aria-expanded","showDropdown","aria-labelledby","children","Navigation","_this3","activeKey","df","key","$","hasClass","trigger","removeClass","Navigation_NavItem","handleClick","bind","Navigation_NavDropdown","components_Home","components_Contact","components_ImputerI","components_ImputerII","components_ImputerIII","components_Comparing","components_EndToEnd","React","App","components_Navigation","Boolean","hostname","match","ReactDOM","render","src_App_0","document","getElementById","navigator","serviceWorker","ready","then","registration","unregister"],"mappings":"oQAYeA,mLARX,OACEC,EAAAC,EAAAC,cAAA,WACEF,EAAAC,EAAAC,cAAA,8CAJcC,8CCGhBC,mLAUK,IAAAC,EACqBC,KAAKC,MAAzBC,EADDH,EACCG,SAAUC,EADXJ,EACWI,MAClB,OACET,EAAAC,EAAAC,cAACQ,EAAA,EAAD,CAAmBF,SAAUA,EAAUG,MAAOC,SAC3CH,UAdeI,iBAAlBT,EAMGU,aAAe,CACpBN,SAAU,MAaCJ,QCqKAW,mLANX,OACIf,EAAAC,EAAAC,cAACc,EAAAf,EAAD,CAAegB,OArLZ,41UAqL2BC,YAAY,EAAOC,UAAW,CAACC,KAAMhB,YAHxDD,aCpCFkB,mLA1DX,OACIrB,EAAAC,EAAAC,cAAA,OAAKoB,UAAU,gCACbtB,EAAAC,EAAAC,cAAA,OAAKoB,UAAU,iBACXtB,EAAAC,EAAAC,cAACc,EAAAf,EAAD,CAAegB,OAtFZ,61BAsFmCC,YAAY,EAAOC,UAAW,CAACC,KAAMhB,MAE/EJ,EAAAC,EAAAC,cAAA,OAAKoB,UAAU,cACXtB,EAAAC,EAAAC,cAACc,EAAAf,EAAD,CAAegB,OAtEf,izCAsEmCC,YAAY,EAAOC,UAAW,CAACC,KAAMhB,MAE5EJ,EAAAC,EAAAC,cAAA,OAAKoB,UAAU,oBACbtB,EAAAC,EAAAC,cAACc,EAAAf,EAAD,CAAegB,OAvBZ,4CAuBiCC,YAAY,EAAOC,UAAW,CAACC,KAAMhB,KACzEJ,EAAAC,EAAAC,cAAA,SAAOqB,OAAO,IAAID,UAAU,aAC1BtB,EAAAC,EAAAC,cAAA,aACIF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,eACAF,EAAAC,EAAAC,cAAA,iBAGJF,EAAAC,EAAAC,cAAA,aACIF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,sBACAF,EAAAC,EAAAC,cAAA,uBAEAF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,sBACAF,EAAAC,EAAAC,cAAA,uBAEAF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,sBACAF,EAAAC,EAAAC,cAAA,uBAEAF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,sBACAF,EAAAC,EAAAC,cAAA,uBAEAF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,sBACAF,EAAAC,EAAAC,cAAA,uBAEAF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,sBACAF,EAAAC,EAAAC,cAAA,kBAEAF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,sBACAF,EAAAC,EAAAC,cAAA,0BAKRF,EAAAC,EAAAC,cAAA,OAAKoB,UAAU,qBACXtB,EAAAC,EAAAC,cAACc,EAAAf,EAAD,CAAegB,OA1Db,mDA0DmCC,YAAY,EAAOC,UAAW,CAACC,KAAMhB,KAC1EJ,EAAAC,EAAAC,cAAA,OAAKsB,IAAI,YAAYC,IAAI,8FArDjBtB,aCkXPuB,mLApJX,OACE1B,EAAAC,EAAAC,cAAA,OAAKoB,UAAU,aACXtB,EAAAC,EAAAC,cAACc,EAAAf,EAAD,CAAegB,OAlTf,k0BAkT+BC,YAAY,EAAOC,UAAW,CAACC,KAAMhB,KACpEJ,EAAAC,EAAAC,cAACc,EAAAf,EAAD,CAAegB,OAxSb,wiCAwS+BC,YAAY,EAAOC,UAAW,CAACC,KAAMhB,KACtEJ,EAAAC,EAAAC,cAAA,OAAKsB,IAAI,oBAAoBC,IAAI,oFACjCzB,EAAAC,EAAAC,cAACc,EAAAf,EAAD,CAAegB,OA9Pd,g5DA8P+BC,YAAY,EAAOC,UAAW,CAACC,KAAMhB,KACrEJ,EAAAC,EAAAC,cAACc,EAAAf,EAAD,CAAegB,OA5NX,i/CA4N+BC,YAAY,EAAOC,UAAW,CAACC,KAAMhB,KACxEJ,EAAAC,EAAAC,cAAA,SAAOqB,OAAO,IAAID,UAAU,aACxBtB,EAAAC,EAAAC,cAAA,aACAF,EAAAC,EAAAC,cAAA,UACIF,EAAAC,EAAAC,cAAA,mBACAF,EAAAC,EAAAC,cAAA,eACAF,EAAAC,EAAAC,cAAA,iBAGJF,EAAAC,EAAAC,cAAA,aACIF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,UAAIF,EAAAC,EAAAC,cAAA,6BACJF,EAAAC,EAAAC,cAAA,iBACAF,EAAAC,EAAAC,cAAA,oBAIRF,EAAAC,EAAAC,cAACc,EAAAf,EAAD,CAAegB,OAnNX,s2CAmN+BC,YAAY,EAAOC,UAAW,CAACC,KAAMhB,KACxEJ,EAAAC,EAAAC,cAAA,SAAOqB,OAAO,IAAID,UAAU,aAC5BtB,EAAAC,EAAAC,cAAA,aACIF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,mBACAF,EAAAC,EAAAC,cAAA,eACAF,EAAAC,EAAAC,cAAA,iBAGJF,EAAAC,EAAAC,cAAA,aACIF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,UAAIF,EAAAC,EAAAC,cAAA,6BACJF,EAAAC,EAAAC,cAAA,eACAF,EAAAC,EAAAC,cAAA,kBAIJF,EAAAC,EAAAC,cAACc,EAAAf,EAAD,CAAegB,OA3LT,ouEA2L+BC,YAAY,EAAOC,UAAW,CAACC,KAAMhB,KAC1EJ,EAAAC,EAAAC,cAAA,SAAOqB,OAAO,IAAID,UAAU,aACxBtB,EAAAC,EAAAC,cAAA,aACIF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,eACAF,EAAAC,EAAAC,cAAA,iBAGJF,EAAAC,EAAAC,cAAA,aACIF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,sBACAF,EAAAC,EAAAC,cAAA,uBAEAF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,uBACAF,EAAAC,EAAAC,cAAA,wBAEAF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,uBACAF,EAAAC,EAAAC,cAAA,uBAEAF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,sBACAF,EAAAC,EAAAC,cAAA,uBAEAF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,sBACAF,EAAAC,EAAAC,cAAA,uBAEAF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,iBACAF,EAAAC,EAAAC,cAAA,kBAEAF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,uBACAF,EAAAC,EAAAC,cAAA,uBAEAF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,uBACAF,EAAAC,EAAAC,cAAA,kBAEAF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,sBACAF,EAAAC,EAAAC,cAAA,kBAEAF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,uBACAF,EAAAC,EAAAC,cAAA,yBAIRF,EAAAC,EAAAC,cAACc,EAAAf,EAAD,CAAegB,OAxLV,4UAwL+BC,YAAY,EAAOC,UAAW,CAACC,KAAMhB,KACzEJ,EAAAC,EAAAC,cAAA,SAAOqB,OAAO,IAAID,UAAU,aACxBtB,EAAAC,EAAAC,cAAA,aACIF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,eACAF,EAAAC,EAAAC,cAAA,iBAGJF,EAAAC,EAAAC,cAAA,aACIF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,sBACAF,EAAAC,EAAAC,cAAA,uBAEAF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,uBACAF,EAAAC,EAAAC,cAAA,wBAEAF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,uBACAF,EAAAC,EAAAC,cAAA,uBAEAF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,sBACAF,EAAAC,EAAAC,cAAA,uBAEAF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,sBACAF,EAAAC,EAAAC,cAAA,uBAEAF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,sBACAF,EAAAC,EAAAC,cAAA,uBAEAF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,uBACAF,EAAAC,EAAAC,cAAA,uBAEAF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,uBACAF,EAAAC,EAAAC,cAAA,uBAEAF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,sBACAF,EAAAC,EAAAC,cAAA,uBAEAF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,uBACAF,EAAAC,EAAAC,cAAA,yBAIRF,EAAAC,EAAAC,cAACc,EAAAf,EAAD,CAAegB,OA5NV,mjIA4N+BC,YAAY,EAAOC,UAAW,CAACC,KAAMhB,aAhJ9DD,aCtSNwB,mLANX,OACE3B,EAAAC,EAAAC,cAAA,yCAHgBC,aCQPyB,mLANX,OACE5B,EAAAC,EAAAC,cAAA,0CAHiBC,aCorBV0B,mLA9KT,OACE7B,EAAAC,EAAAC,cAAA,OAAKoB,UAAU,cACbtB,EAAAC,EAAAC,cAAA,OAAKoB,UAAU,iBACbtB,EAAAC,EAAAC,cAACc,EAAAf,EAAD,CAAegB,OAxgBR,ggBAwgB+BC,YAAY,EAAOC,UAAW,CAACC,KAAMhB,MAE7EJ,EAAAC,EAAAC,cAAA,OAAKoB,UAAU,YACbtB,EAAAC,EAAAC,cAACc,EAAAf,EAAD,CAAegB,OA/fX,+WA+f+BC,YAAY,EAAOC,UAAW,CAACC,KAAMhB,KACxEJ,EAAAC,EAAAC,cAACc,EAAAf,EAAD,CAAegB,OAtfT,yzBAsf+BC,YAAY,EAAOC,UAAW,CAACC,KAAMhB,KAC1EJ,EAAAC,EAAAC,cAACc,EAAAf,EAAD,CAAegB,OA1dV,0GA0d+BC,YAAY,EAAOC,UAAW,CAACC,KAAMhB,KACzEJ,EAAAC,EAAAC,cAAA,OAAKsB,IAAI,cAAcF,UAAU,cAAcG,IAAI,uFACnDzB,EAAAC,EAAAC,cAACc,EAAAf,EAAD,CAAegB,OAndT,qHAmd+BC,YAAY,EAAOC,UAAW,CAACC,KAAMhB,KAC1EJ,EAAAC,EAAAC,cAAA,OAAKsB,IAAI,eAAeF,UAAU,gBAAgBG,IAAI,yFACtDzB,EAAAC,EAAAC,cAACc,EAAAf,EAAD,CAAegB,OA5cb,yVA4c+BC,YAAY,EAAOC,UAAW,CAACC,KAAMhB,KACtEJ,EAAAC,EAAAC,cAAA,OAAKsB,IAAI,kBAAkBF,UAAU,mBAAmBG,IAAI,+EAC5DzB,EAAAC,EAAAC,cAACc,EAAAf,EAAD,CAAegB,OA3bN,8tBA2b+BC,YAAY,EAAOC,UAAW,CAACC,KAAMhB,KAC7EJ,EAAAC,EAAAC,cAAA,OAAKsB,IAAI,sBAAsBF,UAAU,WAAWG,IAAI,iFACxDzB,EAAAC,EAAAC,cAAA,OAAKsB,IAAI,qBAAqBF,UAAU,UAAUG,IAAI,gFACtDzB,EAAAC,EAAAC,cAAA,OAAKsB,IAAI,uBAAuBF,UAAU,YAAYG,IAAI,kFAC1DzB,EAAAC,EAAAC,cAACc,EAAAf,EAAD,CAAegB,OA7Zf,+/BA6Z+BC,YAAY,EAAOC,UAAW,CAACC,KAAMhB,KACpEJ,EAAAC,EAAAC,cAAA,OAAKsB,IAAI,oBAAoBF,UAAU,WAAWG,IAAI,+EACtDzB,EAAAC,EAAAC,cAAA,OAAKsB,IAAI,mBAAmBF,UAAU,UAAUG,IAAI,8EACpDzB,EAAAC,EAAAC,cAAA,OAAKsB,IAAI,qBAAqBF,UAAU,YAAYG,IAAI,gFACxDzB,EAAAC,EAAAC,cAACc,EAAAf,EAAD,CAAegB,OAtXd,05BAsX+BC,YAAY,EAAOC,UAAW,CAACC,KAAMhB,KACrEJ,EAAAC,EAAAC,cAAA,OAAKsB,IAAI,qBAAqBF,UAAU,WAAWG,IAAI,gFACvDzB,EAAAC,EAAAC,cAAA,OAAKsB,IAAI,oBAAoBF,UAAU,UAAUG,IAAI,+EACrDzB,EAAAC,EAAAC,cAAA,OAAKsB,IAAI,sBAAsBF,UAAU,YAAYG,IAAI,iFACzDzB,EAAAC,EAAAC,cAACc,EAAAf,EAAD,CAAegB,OA/UP,sxBA+U+BC,YAAY,EAAOC,UAAW,CAACC,KAAMhB,KAC5EJ,EAAAC,EAAAC,cAAA,SAAOqB,OAAO,IAAID,UAAU,aACxBtB,EAAAC,EAAAC,cAAA,aACIF,EAAAC,EAAAC,cAAA,UACIF,EAAAC,EAAAC,cAAA,oBACAF,EAAAC,EAAAC,cAAA,mBACAF,EAAAC,EAAAC,cAAA,iBACAF,EAAAC,EAAAC,cAAA,gBACAF,EAAAC,EAAAC,cAAA,gBACAF,EAAAC,EAAAC,cAAA,kBAGRF,EAAAC,EAAAC,cAAA,aACIF,EAAAC,EAAAC,cAAA,UACIF,EAAAC,EAAAC,cAAA,UAAIF,EAAAC,EAAAC,cAAA,kBACJF,EAAAC,EAAAC,cAAA,qBACAF,EAAAC,EAAAC,cAAA,qBACAF,EAAAC,EAAAC,cAAA,qBACAF,EAAAC,EAAAC,cAAA,qBACAF,EAAAC,EAAAC,cAAA,sBAEJF,EAAAC,EAAAC,cAAA,UACIF,EAAAC,EAAAC,cAAA,UAAIF,EAAAC,EAAAC,cAAA,6BACJF,EAAAC,EAAAC,cAAA,qBACAF,EAAAC,EAAAC,cAAA,qBACAF,EAAAC,EAAAC,cAAA,qBACAF,EAAAC,EAAAC,cAAA,qBACAF,EAAAC,EAAAC,cAAA,sBAEJF,EAAAC,EAAAC,cAAA,UACIF,EAAAC,EAAAC,cAAA,UAAIF,EAAAC,EAAAC,cAAA,kBACJF,EAAAC,EAAAC,cAAA,qBACAF,EAAAC,EAAAC,cAAA,qBACAF,EAAAC,EAAAC,cAAA,qBACAF,EAAAC,EAAAC,cAAA,qBACAF,EAAAC,EAAAC,cAAA,sBAEJF,EAAAC,EAAAC,cAAA,UACIF,EAAAC,EAAAC,cAAA,UAAIF,EAAAC,EAAAC,cAAA,2BACJF,EAAAC,EAAAC,cAAA,qBACAF,EAAAC,EAAAC,cAAA,qBACAF,EAAAC,EAAAC,cAAA,qBACAF,EAAAC,EAAAC,cAAA,qBACAF,EAAAC,EAAAC,cAAA,sBAEJF,EAAAC,EAAAC,cAAA,UACIF,EAAAC,EAAAC,cAAA,UAAIF,EAAAC,EAAAC,cAAA,iBACJF,EAAAC,EAAAC,cAAA,qBACAF,EAAAC,EAAAC,cAAA,qBACAF,EAAAC,EAAAC,cAAA,qBACAF,EAAAC,EAAAC,cAAA,qBACAF,EAAAC,EAAAC,cAAA,wBAIZF,EAAAC,EAAAC,cAACc,EAAAf,EAAD,CAAegB,OA7WV,+mBA6W+BC,YAAY,EAAOC,UAAW,CAACC,KAAMhB,KACzEJ,EAAAC,EAAAC,cAAA,OAAKsB,IAAI,kBAAkBF,UAAU,cAAcG,IAAI,oFACvDzB,EAAAC,EAAAC,cAAA,OAAKsB,IAAI,gBAAgBF,UAAU,cAAcG,IAAI,kFACrDzB,EAAAC,EAAAC,cAAA,OAAKsB,IAAI,iBAAiBF,UAAU,cAAcG,IAAI,oFAGxDzB,EAAAC,EAAAC,cAAA,OAAKoB,UAAU,WACbtB,EAAAC,EAAAC,cAACc,EAAAf,EAAD,CAAegB,OApVZ,6WAoV+BC,YAAY,EAAOC,UAAW,CAACC,KAAMhB,KACvEJ,EAAAC,EAAAC,cAACc,EAAAf,EAAD,CAAegB,OA3UV,szBA2U+BC,YAAY,EAAOC,UAAW,CAACC,KAAMhB,KACzEJ,EAAAC,EAAAC,cAACc,EAAAf,EAAD,CAAegB,OA/SX,wGA+S+BC,YAAY,EAAOC,UAAW,CAACC,KAAMhB,KACxEJ,EAAAC,EAAAC,cAAA,OAAKsB,IAAI,aAAaF,UAAU,cAAeG,IAAI,sFACnDzB,EAAAC,EAAAC,cAACc,EAAAf,EAAD,CAAegB,OAxSV,mHAwS+BC,YAAY,EAAOC,UAAW,CAACC,KAAMhB,KACzEJ,EAAAC,EAAAC,cAAA,OAAKsB,IAAI,cAAcF,UAAU,gBAAgBG,IAAI,wFACrDzB,EAAAC,EAAAC,cAACc,EAAAf,EAAD,CAAegB,OAjSd,mVAiS+BC,YAAY,EAAOC,UAAW,CAACC,KAAMhB,KACrEJ,EAAAC,EAAAC,cAAA,OAAKsB,IAAI,iBAAiBF,UAAU,mBAAmBG,IAAI,+EAC3DzB,EAAAC,EAAAC,cAACc,EAAAf,EAAD,CAAegB,OAhRP,otBAgR+BC,YAAY,EAAOC,UAAW,CAACC,KAAMhB,KAC5EJ,EAAAC,EAAAC,cAAA,OAAKsB,IAAI,qBAAqBF,UAAU,WAAWG,IAAI,gFACvDzB,EAAAC,EAAAC,cAAA,OAAKsB,IAAI,oBAAoBF,UAAU,UAAUG,IAAI,+EACrDzB,EAAAC,EAAAC,cAAA,OAAKsB,IAAI,sBAAsBF,UAAU,YAAYG,IAAI,iFACzDzB,EAAAC,EAAAC,cAACc,EAAAf,EAAD,CAAegB,OAjPhB,i/BAiP+BC,YAAY,EAAOC,UAAW,CAACC,KAAMhB,KACnEJ,EAAAC,EAAAC,cAAA,OAAKsB,IAAI,mBAAmBF,UAAU,WAAWG,IAAI,8EACrDzB,EAAAC,EAAAC,cAAA,OAAKsB,IAAI,kBAAkBF,UAAU,UAAUG,IAAI,6EACnDzB,EAAAC,EAAAC,cAAA,OAAKsB,IAAI,oBAAoBF,UAAU,YAAYG,IAAI,+EACvDzB,EAAAC,EAAAC,cAACc,EAAAf,EAAD,CAAegB,OA1Mf,44BA0M+BC,YAAY,EAAOC,UAAW,CAACC,KAAMhB,KACpEJ,EAAAC,EAAAC,cAAA,OAAKsB,IAAI,oBAAoBF,UAAU,WAAWG,IAAI,+EACtDzB,EAAAC,EAAAC,cAAA,OAAKsB,IAAI,mBAAmBF,UAAU,UAAUG,IAAI,8EACpDzB,EAAAC,EAAAC,cAAA,OAAKsB,IAAI,qBAAqBF,UAAU,YAAYG,IAAI,gFACxDzB,EAAAC,EAAAC,cAACc,EAAAf,EAAD,CAAegB,OAnKR,qwBAmK+BC,YAAY,EAAOC,UAAW,CAACC,KAAMhB,KAC3EJ,EAAAC,EAAAC,cAAA,SAAOqB,OAAO,IAAID,UAAU,aACxBtB,EAAAC,EAAAC,cAAA,aACIF,EAAAC,EAAAC,cAAA,UACIF,EAAAC,EAAAC,cAAA,oBACAF,EAAAC,EAAAC,cAAA,mBACAF,EAAAC,EAAAC,cAAA,iBACAF,EAAAC,EAAAC,cAAA,gBACAF,EAAAC,EAAAC,cAAA,gBACAF,EAAAC,EAAAC,cAAA,kBAGRF,EAAAC,EAAAC,cAAA,aACIF,EAAAC,EAAAC,cAAA,UACIF,EAAAC,EAAAC,cAAA,UAAIF,EAAAC,EAAAC,cAAA,kBACJF,EAAAC,EAAAC,cAAA,qBACAF,EAAAC,EAAAC,cAAA,qBACAF,EAAAC,EAAAC,cAAA,qBACAF,EAAAC,EAAAC,cAAA,qBACAF,EAAAC,EAAAC,cAAA,sBAEJF,EAAAC,EAAAC,cAAA,UACIF,EAAAC,EAAAC,cAAA,UAAIF,EAAAC,EAAAC,cAAA,6BACJF,EAAAC,EAAAC,cAAA,qBACAF,EAAAC,EAAAC,cAAA,qBACAF,EAAAC,EAAAC,cAAA,qBACAF,EAAAC,EAAAC,cAAA,qBACAF,EAAAC,EAAAC,cAAA,sBAEJF,EAAAC,EAAAC,cAAA,UACIF,EAAAC,EAAAC,cAAA,UAAIF,EAAAC,EAAAC,cAAA,kBACJF,EAAAC,EAAAC,cAAA,qBACAF,EAAAC,EAAAC,cAAA,qBACAF,EAAAC,EAAAC,cAAA,qBACAF,EAAAC,EAAAC,cAAA,qBACAF,EAAAC,EAAAC,cAAA,sBAEJF,EAAAC,EAAAC,cAAA,UACIF,EAAAC,EAAAC,cAAA,UAAIF,EAAAC,EAAAC,cAAA,2BACJF,EAAAC,EAAAC,cAAA,qBACAF,EAAAC,EAAAC,cAAA,qBACAF,EAAAC,EAAAC,cAAA,qBACAF,EAAAC,EAAAC,cAAA,qBACAF,EAAAC,EAAAC,cAAA,sBAEJF,EAAAC,EAAAC,cAAA,UACIF,EAAAC,EAAAC,cAAA,UAAIF,EAAAC,EAAAC,cAAA,iBACJF,EAAAC,EAAAC,cAAA,qBACAF,EAAAC,EAAAC,cAAA,qBACAF,EAAAC,EAAAC,cAAA,qBACAF,EAAAC,EAAAC,cAAA,qBACAF,EAAAC,EAAAC,cAAA,wBAIZF,EAAAC,EAAAC,cAACc,EAAAf,EAAD,CAAegB,OAjMX,ymBAiM+BC,YAAY,EAAOC,UAAW,CAACC,KAAMhB,KACxEJ,EAAAC,EAAAC,cAAA,OAAKsB,IAAI,iBAAiBF,UAAU,cAAcG,IAAI,mFACtDzB,EAAAC,EAAAC,cAAA,OAAKsB,IAAI,eAAeF,UAAU,cAAcG,IAAI,iFACpDzB,EAAAC,EAAAC,cAAA,OAAKsB,IAAI,gBAAgBF,UAAU,cAAcG,IAAI,2FAxK1CtB,aC7fjB2B,EAAU,SAAAvB,GACd,IAAMwB,EAAUC,OAAOC,SAASC,SAASF,OAAOC,SAASE,OACnDC,EAAe7B,EAAM8B,OAASN,EAAW,kBAAoB,WAC7DO,EAAa/B,EAAMgC,SAAW,oBAAsB,WAC1D,OACEvC,EAAAC,EAAAC,cAAA,MAAIoB,UAAWc,GACbpC,EAAAC,EAAAC,cAAA,KAAGsC,QAAS,kBAAMjC,EAAMiC,WAAWC,KAAMlC,EAAM8B,KAAMf,UAAWgB,GAC7D/B,EAAMmC,KACLnC,EAAM8B,OAASN,EAAY/B,EAAAC,EAAAC,cAAA,QAAMoB,UAAU,WAAhB,aAA8C,MAM7EqB,cACJ,SAAAA,EAAYpC,GAAO,IAAAqC,EAAA,OAAAC,OAAAC,EAAA,EAAAD,CAAAvC,KAAAqC,IACjBC,EAAAC,OAAAE,EAAA,EAAAF,CAAAvC,KAAAuC,OAAAG,EAAA,EAAAH,CAAAF,GAAAM,KAAA3C,KAAMC,KACD2C,MAAQ,CACXC,YAAY,GAHGP,4EAMNQ,GACXA,EAAEC,iBACF/C,KAAKgD,SAAS,SAAAC,GAAS,MAAK,CAC1BJ,YAAaI,EAAUJ,+CAGlB,IAAAK,EAAAlD,KACDmD,EAAoB,iBAAmBnD,KAAK4C,MAAMC,WAAa,QAAU,IAC/E,OACEnD,EAAAC,EAAAC,cAAA,MAAIoB,UAAU,qBACZtB,EAAAC,EAAAC,cAAA,KAAGoB,UAAU,2BAA2BoC,GAAG,iBAAiBC,KAAK,SAASC,cAAY,WACpFC,gBAAc,OAAOC,gBAAc,QACnCtB,QAAS,SAACY,GAAOI,EAAKO,aAAaX,KAClC9C,KAAKC,MAAMmC,MAEd1C,EAAAC,EAAAC,cAAA,OAAKoB,UAAWmC,EAAmBO,kBAAgB,kBAChD1D,KAAKC,MAAM0D,kBAvBI9D,aA6FX+D,cA7Db,SAAAA,EAAY3D,GAAO,IAAA4D,EAAA,OAAAtB,OAAAC,EAAA,EAAAD,CAAAvC,KAAA4D,IAEbC,EAAAtB,OAAAE,EAAA,EAAAF,CAAAvC,KAAAuC,OAAAG,EAAA,EAAAH,CAAAqB,GAAAjB,KAAA3C,KAAMC,KAGD2C,MAAQ,CACXkB,UAAW,EACXC,GAAI,0BAPOF,2EAYPG,GAEVhE,KAAKgD,SAAS,CAACc,UAAWE,IAMvBC,IAAE,kBAAkBC,SAAS,UAC9BD,IAAG,kBAAmBE,QAAS,SAC7BF,IAAE,kBAAkBG,YAAY,0CAIpC,OACC1E,EAAAC,EAAAC,cAAA,OAAKoB,UAAU,aACdtB,EAAAC,EAAAC,cAAA,OAAKoB,UAAU,2BACbtB,EAAAC,EAAAC,cAAA,KAAGoB,UAAU,eAAemB,KAAMnC,KAAK4C,MAAMmB,IAA7C,cACArE,EAAAC,EAAAC,cAAA,OAAKoB,UAAU,2BAA2BoC,GAAG,0BAC3C1D,EAAAC,EAAAC,cAAA,MAAIoB,UAAU,sBACZtB,EAAAC,EAAAC,cAACyE,EAAD,CAASjC,KAAK,OAAOF,QAASlC,KAAKsE,YAAYC,KAAKvE,KAAM,KAC1DN,EAAAC,EAAAC,cAACyE,EAAD,CAASjC,KAAK,UAAUF,QAASlC,KAAKsE,YAAYC,KAAKvE,KAAM,KAC7DN,EAAAC,EAAAC,cAAC4E,EAAD,CAAapC,KAAK,aACd1C,EAAAC,EAAAC,cAAA,KAAGoB,UAAU,gBAAgBmB,KAAMnC,KAAKC,MAAM8B,KAAMG,QAASlC,KAAKsE,YAAYC,KAAKvE,KAAM,MAAzF,yBACAN,EAAAC,EAAAC,cAAA,KAAGoB,UAAU,gBAAgBmB,KAAMnC,KAAKC,MAAM8B,KAAMG,QAASlC,KAAKsE,YAAYC,KAAKvE,KAAM,MAAzF,oBACAN,EAAAC,EAAAC,cAAA,KAAGoB,UAAU,gBAAgBmB,KAAMnC,KAAKC,MAAM8B,KAAMG,QAASlC,KAAKsE,YAAYC,KAAKvE,KAAM,MAAzF,qBACAN,EAAAC,EAAAC,cAAA,KAAGoB,UAAU,gBAAgBmB,KAAMnC,KAAK4C,MAAMb,KAAMG,QAASlC,KAAKsE,YAAYC,KAAKvE,KAAM,MAAzF,sBACAN,EAAAC,EAAAC,cAAA,KAAGoB,UAAU,gBAAgBmB,KAAMnC,KAAK4C,MAAMb,KAAMG,QAASlC,KAAKsE,YAAYC,KAAKvE,KAAM,MAAzF,gCACAN,EAAAC,EAAAC,cAAA,KAAGoB,UAAU,gBAAgBmB,KAAMnC,KAAK4C,MAAMb,KAAMG,QAASlC,KAAKsE,YAAYC,KAAKvE,KAAM,MAAzF,2BAKTN,EAAAC,EAAAC,cAAA,OAAKoB,UAAU,WACa,IAAzBhB,KAAK4C,MAAMkB,UAAkBpE,EAAAC,EAAAC,cAAC6E,EAAD,MAAU,KACd,IAAzBzE,KAAK4C,MAAMkB,UAAkBpE,EAAAC,EAAAC,cAAC8E,EAAD,MAAa,KACjB,MAAzB1E,KAAK4C,MAAMkB,UAAoB,eAAiB,KACvB,MAAzB9D,KAAK4C,MAAMkB,UAAoBpE,EAAAC,EAAAC,cAAC+E,EAAD,MAAc,KACpB,MAAzB3E,KAAK4C,MAAMkB,UAAoBpE,EAAAC,EAAAC,cAACgF,EAAD,MAAe,KACrB,MAAzB5E,KAAK4C,MAAMkB,UAAoBpE,EAAAC,EAAAC,cAACiF,EAAD,MAAgB,KACtB,MAAzB7E,KAAK4C,MAAMkB,UAAoBpE,EAAAC,EAAAC,cAACkF,EAAD,MAAe,KACrB,MAAzB9E,KAAK4C,MAAMkB,UAAoBpE,EAAAC,EAAAC,cAACmF,EAAD,MAAc,cAtD9BC,IAAMnF,WC1ChBoF,mLARX,OACEvF,EAAAC,EAAAC,cAAA,WACEF,EAAAC,EAAAC,cAACsF,EAAD,cAJUrF,aCQEsF,QACW,cAA7BzD,OAAOC,SAASyD,UAEe,UAA7B1D,OAAOC,SAASyD,UAEhB1D,OAAOC,SAASyD,SAASC,MACvB,kECXNC,IAASC,OAAO7F,EAAAC,EAAAC,cAAC4F,EAAD,MAASC,SAASC,eAAe,SD0H3C,kBAAmBC,WACrBA,UAAUC,cAAcC,MAAMC,KAAK,SAAAC,GACjCA,EAAaC","file":"static/js/main.8b11b36a.chunk.js","sourcesContent":["import React, { Component } from \"react\";\n \nclass Contact extends Component {\n  render() {\n    return (\n      <div>\n        <h2>THIS IS THE CONTACT PAGE</h2>\n      </div>\n    );\n  }\n}\n \nexport default Contact;","import React, { PureComponent } from \"react\";\nimport PropTypes from \"prop-types\";\nimport SyntaxHighlighter from 'react-syntax-highlighter';\nimport { docco } from 'react-syntax-highlighter/dist/styles/hljs';\n\nclass CodeBlock extends PureComponent {\n  static propTypes = {\n    value: PropTypes.string.isRequired,\n    language: PropTypes.string\n  };\n\n  static defaultProps = {\n    language: null\n  };\n\n  render() {\n    const { language, value } = this.props;\n    return (\n      <SyntaxHighlighter language={language} style={docco}>\n        {value}\n      </SyntaxHighlighter>\n    );\n  }\n}\n\nexport default CodeBlock;","import React, { Component } from \"react\";\nimport ReactMarkdown from \"react-markdown\";\nimport CodeBlock from \"./CodeBlock\";\n\nconst input = `\n## Welcome to Autoimpute!\n[![PyPI version](https://badge.fury.io/py/autoimpute.svg)](https://badge.fury.io/py/autoimpute) [![Build Status](https://travis-ci.com/kearnz/autoimpute.svg?branch=master)](https://travis-ci.com/kearnz/autoimpute) [![Documentation Status](https://readthedocs.org/projects/autoimpute/badge/?version=latest)](https://autoimpute.readthedocs.io/en/latest/?badge=latest) [![MIT license](https://img.shields.io/badge/License-MIT-blue.svg)](https://lbesson.mit-license.org/) [![Python 3.6+](https://img.shields.io/badge/python-3.6+-blue.svg)](https://www.python.org/downloads/release/python-360/)\n\n[Autoimpute](https://pypi.org/project/autoimpute/) is a Python package for analysis and implementation of <b>Imputation Methods!</b>\n\n[Check out our docs](https://autoimpute.readthedocs.io/en/latest/) to pick up the developer guide.\n\n### Installation\n* \\`Autoimpute\\` is now **registered with PyPI!** Download with \\`pip install autoimpute\\`.\n* The latest version of \\`Autoimpute\\` is \\`0.11.3\\`.\n* If \\`pip\\` cached an older version, try \\`pip install --no-cache-dir --upgrade autoimpute\\`.\n* If you want to work with the development branch, use the script below:\n\n### Motivation\nMost machine learning algorithms expect clean and complete datasets, but real-world data is messy and missing. Unfortunately, handling missing data is quite complex, so programming languages generally punt this responsibility to the end user. By default, R drops all records with missing data - a method that is easy to implement but often problematic in practice. For richer imputation strategies, R has multiple packages to deal with missing data (\\`MICE\\`, \\`Amelia\\`, \\`TSImpute\\`, etc.). Python users are not as fortunate. Python's \\`scikit-learn\\` throws a runtime error when an end user deploys models on datasets with missing records, and few third-party packages exist to handle imputation end-to-end.\n\nTherefore, this package aids the Python user by providing more clarity to the imputation process, making imputation methods more accessible, and measuring the impact imputation methods have in supervised regression and classification. In doing so, this package brings missing data imputation methods to the Python world and makes them work nicely in Python machine learning projects (and specifically ones that utilize \\`scikit-learn\\`). Lastly, this package provides its own implementation of supervised machine learning methods that extend both \\`scikit-learn\\` and \\`statsmodels\\` to mutiply imputed datasets.\n\n### Main Features\n* Utility functions to examine patterns in missing data and decide on relevant features for imputation\n* Missingness classifier and automatic missing data test set generator\n* Native handling for categorical variables (as predictors and targets of imputation)\n* Single and multiple imputation classes for \\`pandas\\` \\`DataFrames\\`\n* Custom visualization support for utility functions and imputation methods\n* Analysis methods and pooled parameter inference using multiply imputed datasets\n* Numerous imputation methods, as specified in the table below:\n\n### Imputation Methods Supported\n\n| Univariate                  | Multivariate                        | Time Series / Interpolation\n| :-------------------------- | :---------------------------------- | ---------------------------\n| Mean                        | Linear Regression                   | Linear \n| Median                      | Binomial Logistic Regression        | Quadratic \n| Mode                        | Multinomial Logistic Regression     | Cubic\n| Random                      | Stochastic Regression               | Polynomial\n| Norm                        | Bayesian Linear Regression          | Spline\n| Categorical                 | Bayesian Binary Logistic Regression | Time-weighted\n|                             | Predictive Mean Matching            | Next Obs Carried Backward\n|                             | Local Residual Draws                | Last Obs Carried Forward\n\n### Todo\n* Additional cross-sectional methods, including random forest, KNN, EM, and maximum likelihood\n* Additional time-series methods, including EWMA, ARIMA, Kalman filters, and state-space models\n* Extended support for visualization of missing data patterns, imputation methods, and analysis models\n* Additional support for analysis metrics and analyis models after multiple imputation\n* Multiprocessing and GPU support for larger datasets, as well as integration with \\`dask\\` DataFrames\n\n### Example Usage\nAutoimpute is designed to be user friendly and flexible. When performing imputation, Autoimpute fits directly into \\`scikit-learn\\` machine learning projects. Imputers inherit from sklearn's \\`BaseEstimator\\` and \\`TransformerMixin\\` and implement \\`fit\\` and \\`transform\\` methods, making them valid Transformers in an sklearn pipeline.\n\nRight now, there are two \\`Imputer\\` classes we'll work with:\n\\`\\`\\`python\nfrom autoimpute.imputations import SingleImputer, MultipleImputer\nsi = SingleImputer() # imputation methods, passing through the data once\nmi = MultipleImputer() # imputation methods, passing through the data multiple times\n\\`\\`\\`\n\nImputations can be as simple as:\n\\`\\`\\`python\n# simple example using default instance of MultipleImputer\nimp = MultipleImputer()\n\n# fit transform returns a generator by default, calculating each imputation method lazily\nimp.fit_transform(data)\n\\`\\`\\`\n\nOr quite complex, such as:\n\\`\\`\\`python\n# create a complex instance of the MultipleImputer\n# Here, we specify strategies by column and predictors for each column\n# We also specify what additional arguments any pmm strategies should take\nimp = MultipleImputer(\n    n=10,\n    strategy={\"salary\": \"pmm\", \"gender\": \"bayesian binary logistic\", \"age\": \"norm\"},\n    predictors={\"salary\": \"all\", \"gender\": [\"salary\", \"education\", \"weight\"]},\n    imp_kwgs={\"pmm\": {\"fill_value\": \"random\"}},\n    visit=\"left-to-right\",\n    return_list=True\n)\n\n# Because we set return_list=True, imputations are done all at once, not evaluated lazily.\n# This will return M*N, where M is the number of imputations and N is the size of original dataframe.\nimp.fit_transform(data)\n\\`\\`\\`\n\nAutoimpute also extends supervised machine learning methods from \\`scikit-learn\\` and \\`statsmodels\\` to apply them to multiply imputed datasets (using the \\`MultipleImputer\\` under the hood). Right now, Autoimpute supports linear regression and binary logistic regression. Additional supervised methods are currently under development.\n\nAs with Imputers, Autoimpute's analysis methods can be simple or complex:\n\\`\\`\\`python\nfrom autoimpute.analysis import MiLinearRegression\n\n# By default, use statsmodels OLS and MultipleImputer()\nsimple_lm = MiLinearRegression()\n\n# fit the model on each multiply imputed dataset and pool parameters\nsimple_lm.fit(X_train, y_train)\n\n# get summary of fit, which includes pooled parameters under Rubin's rules\n# also provides diagnostics related to analysis after multiple imputation\nsimple_lm.summary()\n\n# make predictions on a new dataset using pooled parameters\npredictions = simple_lm.predict(X_test)\n\n# Control both the regression used and the MultipleImputer itself\nmultiple_imputer_arguments = dict(\n    n=3,\n    strategy={\"salary\": \"pmm\", \"gender\": \"bayesian binary logistic\", \"age\": \"norm\"},\n    predictors={\"salary\": \"all\", \"gender\": [\"salary\", \"education\", \"weight\"]},\n    imp_kwgs={\"pmm\": {\"fill_value\": \"random\"}},\n    visit=\"left-to-right\"\n)\ncomplex_lm = MiLinearRegression(\n    model_lib=\"sklearn\", # use sklearn linear regression\n    mi_kwgs=multiple_imputer_arguments # control the multiple imputer\n)\n\n# fit the model on each multiply imputed dataset\ncomplex_lm.fit(X_train, y_train)\n\n# get summary of fit, which includes pooled parameters under Rubin's rules\n# also provides diagnostics related to analysis after multiple imputation\ncomplex_lm.summary()\n\n# make predictions on new dataset using pooled parameters\npredictions = complex_lm.predict(X_test)\n\\`\\`\\`\n\nNote that we can also pass a pre-specified \\`MultipleImputer\\` to either analysis model instead of using \\`mi_kwgs\\`. The option is ours, and it's a matter of preference. If we pass a pre-specified \\`MultipleImputer\\`, anything in \\`mi_kwgs\\` is ignored, although the \\`mi_kwgs\\` argument is still validated.\n\n\\`\\`\\`python\nfrom autoimpute.imputations import MultipleImputer\nfrom autoimpute.analysis import MiLinearRegression\n\n# create a multiple imputer first\ncustom_imputer = MultipleImputer(n=3, strategy=\"pmm\", return_list=True)\n\n# pass the imputer to a linear regression model\ncomplex_lm = MiLinearRegression(mi=custom_imputer, model_lib=\"statsmodels\")\n\n# proceed the same as the previous examples\ncomplex_lm.fit(X_train, y_train).predict(X_test)\ncomplex_lm.summary()\n\\`\\`\\`\n\n### Versions and Dependencies\n* Python 3.6+\n* Dependencies:\n    - \\`numpy\\` >= 1.15.4\n    - \\`scipy\\` >= 1.2.1\n    - \\`pandas\\` >= 0.20.3\n    - \\`statsmodels\\` >= 0.9.0\n    - \\`scikit-learn\\` >= 0.20.2\n    - \\`xgboost\\` >= 0.83\n    - \\`pymc3\\` >= 3.5\n    - \\`seaborn\\` >= 0.9.0\n    - \\`missingno\\` >= 0.4.1\n\n*A note for Windows Users*:\n* Autoimpute works on Windows but users may have trouble with pymc3 for bayesian methods. [(See discourse)](https://discourse.pymc.io/t/an-error-message-about-cant-pickle-fortran-objects/1073)\n* Users may receive a runtime error \\`‘can’t pickle fortran objects’\\` when sampling using multiple chains.\n* There are a couple of things to do to try to overcome this error:\n    - Reinstall theano and pymc3. Make sure to delete .theano cache in your home folder.\n    - Upgrade joblib in the process, which is reponsible for generating the error (pymc3 uses joblib under the hood).\n    - Set \\`cores=1\\` in \\`pm.sample\\`. This should be a last resort, as it means posterior sampling will use 1 core only. Not using multiprocessing will slow down bayesian imputation methods significantly.\n* Reach out and let us know if you've worked through this issue successfully on Windows and have a better solution!\n\n### License\nDistributed under the MIT license. See [LICENSE](https://github.com/kearnz/autoimpute/blob/master/LICENSE) for more information.\n\n### Contributing\nGuidelines for contributing to our project. See [CONTRIBUTING](https://github.com/kearnz/autoimpute/blob/master/CONTRIBUTING.md) for more information.\n\n### Contributor Code of Conduct\nAdapted from Contributor Covenant, version 1.0.0. See [Code of Conduct](https://github.com/kearnz/autoimpute/blob/master/CODE_OF_CONDUCT.md) for more information.\n`\n\nclass Home extends Component {\n  render() {\n    return (\n        <ReactMarkdown source={input} escapeHtml={false} renderers={{code: CodeBlock}} />\n    );\n  }\n}\n \nexport default Home;","import React, { Component } from \"react\";\nimport ReactMarkdown from \"react-markdown\";\nimport CodeBlock from \"./CodeBlock\";\n\n// HEADER TO START THE TUTORIAL\nconst inputHeader01 = `\n## Using Autoimpute to Compare Imputation Methods\n\nThis tutorial examimes the effect of imputation methods from the \\`Autoimpute\\` package. The tutorial includes:  \n\n1. Generating Data  \n2. Exploring Missingness  \n3. Imputation Methods  \n4. Impact of imputation on Covariance and Correlation  \n\n### 1. Generating Data\n* In the section below, we generate two variables, **x** and **y**, that are positively correlated but display heteroscedasticity.\n* Thus, **x** and **y** get larger (or smaller) together. As a result, the variance between the two variables is not constant.     \n* We then introduce 30% missingness within **y**. **x** remains completely observed.  \n* The code on the left generates the data and creates a function to visualize the data.  \n* The code on the right displays the resulting dataframe and its associated plot.   \n`\n\n// FIRST CODE BLOCK\nconst inputCode1 = `\n\\`\\`\\`python\n'''Simulating data and defining a joint plot b/w two variables'''\n\n# plotting specification and imports needed\n%matplotlib inline\nimport numpy as np\nimport pandas as pd\nfrom scipy.stats import norm, binom\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# seed to follow along\nnp.random.seed(654654)\n\n# generate 1500 data points\nN = np.arange(1500)\n\n# create correlated, heteroskedastic random variables\na = 0\nb = 1\neps = np.array([norm(0, n).rvs() for n in N])\ny = (a + b*N + eps) / 100                         \nx = (N + norm(10, 10).rvs(len(N))) / 100\n \n# 30% missingness created artificially\ny[binom(1, 0.3).rvs(len(N)) == 1] = np.nan\n\n# collect results in a dataframe \ndata_het_miss = pd.DataFrame({\"y\": y, \"x\": x})\n\n# create a scatter plot function to display the results of our dataframe\ndef scatter_dists(data, x=\"x\", y=\"y\", a=0.5, joints_color=\"navy\", \n                  markers=\"o\", marginals=dict(rug=True, kde=True)):\n\n    sns.set(context=\"talk\")\n    joint_kws = dict(\n        facecolor=joints_color,\n        edgecolor=joints_color,\n        marker=markers\n    )\n    sns.jointplot(\n        x=x, y=y, data=data, alpha=a, height=8.27,\n        joint_kws=joint_kws, marginal_kws=marginals\n    )\n\\`\\`\\`\n`\n\nconst df_header01 = `\n\\`\\`\\`python\ndata_het_miss.head(7)\n\\`\\`\\`\n`\n\nconst df_scatter01 = `\n\\`\\`\\`python\nscatter_dists(data_het_miss)\n\\`\\`\\`\n`\n\nclass Comparing extends Component {\n    render() {\n      return (\n          <div className=\"comparing-imputation-methods\">\n            <div className=\"cim-header-01\">\n                <ReactMarkdown source={inputHeader01} escapeHtml={false} renderers={{code: CodeBlock}} />\n            </div>\n            <div className=\"cim-code-1\">\n                <ReactMarkdown source={inputCode1} escapeHtml={false} renderers={{code: CodeBlock}} />\n            </div>\n            <div className=\"cim-table-code-1\">\n              <ReactMarkdown source={df_header01} escapeHtml={false} renderers={{code: CodeBlock}} />\n              <table border=\"1\" className=\"dataframe\">\n                <thead>\n                    <tr>\n                    <th>x</th>\n                    <th>y</th>\n                    </tr>\n                </thead>\n                <tbody>\n                    <tr>\n                    <td>0.295288</td>\n                    <td>0.000000</td>\n                    </tr>\n                    <tr>\n                    <td>0.086210</td>\n                    <td>0.002255</td>\n                    </tr>\n                    <tr>\n                    <td>0.227369</td>\n                    <td>0.003869</td>\n                    </tr>\n                    <tr>\n                    <td>0.194216</td>\n                    <td>0.046370</td>\n                    </tr>\n                    <tr>\n                    <td>0.094630</td>\n                    <td>0.081440</td>\n                    </tr>\n                    <tr>\n                    <td>0.292320</td>\n                    <td>NaN</td>\n                    </tr>\n                    <tr>\n                    <td>0.198131</td>\n                    <td>0.067222</td>\n                    </tr>\n                </tbody>\n              </table>\n            </div>\n            <div className=\"cim-df-scatter-01\">\n                <ReactMarkdown source={df_scatter01} escapeHtml={false} renderers={{code: CodeBlock}} />\n                <img alt=\"scatter01\" src=\"https://kearnz.github.io/autoimpute-tutorials/img/comparing/cim-df-scatter01.png\"></img>\n            </div>\n          </div>\n      );\n    }\n  }\n   \n  export default Comparing;","import React, { Component } from \"react\";\nimport ReactMarkdown from \"react-markdown\";\nimport CodeBlock from \"./CodeBlock\";\n\nconst header = `\n## Getting the Most out of the Imputer Classes: Part I\n---\nThis tutorial is part I of a comprehensive overview of \\`Autoimpute\\` Imputers. It includes:  \n1. Motivation for Imputation in the First Place  \n2. The Design Considerations behind Autoimpute Imputers  \n\n### 1. Motivation for Imputation in the First Place\nLet's revisit why multiple imputation is necessary. A user wants to perform analysis on a dataset using some sort of **analysis model** such as linear regression or logistic regression. The dataset of interest contains one or more predictors, **X**, and some response **y**. The analysis model produces a function that best explains the relationship between **X** and **y**. Let's generate some sample data below. To keep things simple, our data set contains just one predictor, **x**, and a response **y**.\n`\n\nconst codePlot = `\n\n\\`\\`\\`python\n# imports\nimport numpy as np\nimport pandas as pd\nfrom scipy.stats import norm, binom\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nsns.set(context=\"talk\", rc={'figure.figsize':(11.7,8.27)})\n\n# helper functions used throughout this project\nprint_header = lambda msg: print(f\"{msg}\\n{'-'*len(msg)}\")\n\n# seed to follow along\nnp.random.seed(654654)\n\n# generate 1500 data points\nN = np.arange(1500)\n\n# helper function for this data\nvary = lambda v: np.random.choice(np.arange(v))\n\n# create correlated, random variables\na = 2\nb = 1/2\neps = np.array([norm(0, vary(50)).rvs() for n in N])\ny = (a + b*N + eps) / 100                         \nx = (N + norm(10, vary(250)).rvs(len(N))) / 100\n \n# 20% missing in x, 30% missing in y\nx[binom(1, 0.2).rvs(len(N)) == 1] = np.nan\ny[binom(1, 0.3).rvs(len(N)) == 1] = np.nan\n\n# collect results in a dataframe \ndata_miss = pd.DataFrame({\"y\": y, \"x\": x})\nsns.scatterplot(x=\"x\", y=\"y\", data=data_miss)\nplt.show()\n\\`\\`\\`\n\n`\n\nconst partOne = `\nThe plot suggests a linear relationship may exist between **x** and **y**. Let's fit a linear model to estimate that relationship.\n\n\n\\`\\`\\`python\nfrom sklearn.linear_model import LinearRegression\n\n# prep for regression\nX = data_miss.x.values.reshape(-1, 1) # reshape because one feature only\ny = data_miss.y\nlm = LinearRegression()\n\n# try to fit the model\nprint_header(\"Fitting linear model to estimate relationship between X and y\")\ntry:\n    lm.fit(X, y)\nexcept ValueError as ve:\n    print(f\"{ve.__class__.__name__}: {ve}\")\n\\`\\`\\`\n\n    Fitting linear model to estimate relationship between X and y\n    -------------------------------------------------------------\n    ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n\n\n#### What Happened?\n\\`sklearn\\` threw a ValueError when we tried to fit a linear regression. The error occurred because our **dataset has missing data**. In our case, 20% of observations are missing in our predictor, and 30% of observations are missing in our response. \\`sklearn\\` cannot fit the analysis model unless our dataset is complete! That's no good - we can't model the relationship in our data, nor can we make predictions when new data arrives.\n\n#### What do we Do?\nIn order to proceed, we **need to handle the missing data in some way**. One option is simply removing records with missing data. This strategy allows the analysis model to run, but it may negatively affect the inference from that model. For now, we'll recommend against dropping missing records.\n\nIf we don't drop missing records, **then we must impute them**. Imputing data means coming up with plausible values to fill in missing records, which we must do to enable our analysis model to run. **Performing imputations is the primary concern of Autoimpute**. The next section introduces Autoimpute Imputers and familiarizes the reader with Autoimpute's package design.\n\n`\n\nconst partTwoOne = `\n\n### 2. The Design Considerations behind Autoimpute Imputers\nWe designed Autoimpute Imputers with three goals in mind:  \n* **Make Imputation Easy**. Imputation can be done in one line of code.  \n* **Make Imputation Familiar to Python Users.** Autoimpute Imputers follows the design patterns of sklearn.  \n* **Make Imputation Flexible**. Use an Imputer's default arguments or fine-tune Imputers case-by-case.  \n\nLet's explore each objective. We'll use the same dataset as above and stick with the \\`SingleImputer\\` for now. The \\`MutlipleImputer\\` extends the \\`SingleImputer\\` and therefore contains all the arguments that the \\`SingleImputer\\` does. Therefore, we will explain design considerations using the \\`SingleImputer\\`. In Part III of this series, we'll address additional arguments of and considerations for the \\`MultipleImputer\\`.\n\n#### 2.1. Make Imputation Easy\n\nAs promised, we can impute a dataset with exactly one line of code. In the code section below, we'll demonstrate the one line of code that imputes all missing data in a dataset. First, we'll observe how many records are missing. Then, we'll perform imputation and verify that missing records have been imputed.\n\n\n\\`\\`\\`python\n# amount of missing data before imputation\nprint_header(\"Amount of data missing before imputation takes place\")\npd.DataFrame(data_miss.isnull().sum(), columns=[\"records missing\"]).T\n\\`\\`\\`\n\n    Amount of data missing before imputation takes place\n    ----------------------------------------------------\n\n`\n\nconst partTwoTwo = `\n\n\\`\\`\\`python\nfrom autoimpute.imputations import SingleImputer\nprint_header(\"Imputing missing data in one line of code with the default SingleImputer\")\ndata_imputed_once = SingleImputer().fit_transform(data_miss)\nprint(\"Imputation Successful!\")\n\\`\\`\\`\n\n    Imputing missing data in one line of code with the default SingleImputer\n    ------------------------------------------------------------------------\n\n\n    Auto-assigning NUTS sampler...\n    Initializing NUTS using jitter+adapt_diag...\n    Multiprocess sampling (4 chains in 4 jobs)\n    NUTS: [σ, beta, alpha]\n    Sampling 4 chains: 100%|██████████| 6000/6000 [00:03<00:00, 1912.67draws/s]\n    Auto-assigning NUTS sampler...\n    Initializing NUTS using jitter+adapt_diag...\n    Multiprocess sampling (4 chains in 4 jobs)\n    NUTS: [σ, beta, alpha]\n    Sampling 4 chains: 100%|██████████| 6000/6000 [00:03<00:00, 1722.73draws/s]\n\n\n    Imputation Successful!\n\n\n\n\\`\\`\\`python\n# amount of missing data before imputation\nprint_header(\"Amount of data missing after imputation takes place\")\npd.DataFrame(data_imputed_once.isnull().sum(), columns=[\"records missing\"]).T\n\\`\\`\\`\n\n    Amount of data missing after imputation takes place\n    ---------------------------------------------------\n\n\n`\n\nconst partTwoThree = `\n\n### 2.2 Make Imputation Familiar to Python Users\nAutoimpute follows \\`sklearn\\` API design. This design choice comes with a number of benefits:  \n* If you are familiar with \\`sklearn\\`, there is essentially no learning curve to start using \\`Autoimpute\\`.  \n* Imputers inherit from sklearn's BaseEstimator and TransformerMixin and leverage methods from these Parent classes.  \n* Imputers can \\`fit_transform\\` the same dataset, or \\`fit\\` and \\`Imputer\\` to \\`transform\\` new data with the same features.  \n* Imputers fit in sklearn Pipelines (although Autoimpute includes ML models designed for multiply imputed data).  \n\nThe code segments below demonstrate Autoimpute's ease of use and familiarity.\n\nFirst, Autoimpute Imputers inherit from \\`BaseEstimator\\` and \\`TransformerMixin\\` classes from \\`sklearn\\`.\n\n\n\\`\\`\\`python\nprint_header(\"Parent Classes to SingleImputer and MultipleImpuer\")\nprint(list(map(lambda cls_: cls_.__name__, SingleImputer().__class__.__bases__)))\n\\`\\`\\`\n\n    Parent Classes to SingleImputer and MultipleImpuer\n    --------------------------------------------------\n    ['BaseImputer', 'BaseEstimator', 'TransformerMixin']\n\n\nAs with \\`sklearn\\` \\`Transformers\\`, Autoimpute Imputers set smart defaults for all its arguments. Imputers leverage the \\`__repr__\\` special method inherited from the \\`BaseEstimator\\`, so users can quickly examine the default values an \\`Imputer\\` sets.\n\n\n\\`\\`\\`python\nSingleImputer()\n\\`\\`\\`\n\n\n\n\n    SingleImputer(copy=True, imp_kwgs=None, predictors='all', seed=None,\n           strategy='default predictive', visit='default')\n\n\n\nBecause Autoimpute Imputers are valid \\`sklearn\\` \\`Transformers\\`, they implement the \\`fit\\`, \\`transform\\`, and \\`fit_transform\\` methods, which should be familiar to anyone who has preprocessed data using \\`sklearn\\`. The \\`fit\\` step returns an instance of the \\`Imputer\\` class, and the \\`transform\\` step returns a **transformed dataset**. Imputers can fit and transform a dataset in one go by using \\`fit_transform\\`. We demonstrate this process below, transforming our missing dataset using mean imputation.\n\n\n\\`\\`\\`python\nprint_header(\"Original dataset with missing values\")\ndata_miss.head(10)\n\\`\\`\\`\n\n    Original dataset with missing values\n    ------------------------------------\n\n\n\n`\n\nconst partTwoFour = `\n\n\\`\\`\\`python\nprint_header(\"Transforming the missing dataset with mean imputation\")\nimputer = SingleImputer(strategy=\"mean\")\ndata_imputed = imputer.fit_transform(data_miss)\ndata_imputed.head(10)\n\\`\\`\\`\n\n    Transforming the missing dataset with mean imputation\n    -----------------------------------------------------\n\n\n`\n\nconst partTwoFive = `\n\nThe transformed dataset contains imputations in place of previously missing values. Here, we used mean imputation, although we offer many imputation strategies that may be more appropriate. We show these strategies in Part II of this series. We can **easily retrieve the index of the the imputed values** should we want to assess the imputations themselves. The index of imputed values live in the Imputer's \\`imputed_\\` attribute. As with \\`sklearn\\`, public attributes of Imputers contain an underscore suffix.\n\nThe \\`imputed_\\` attribute returns a dictionary, where each key is a column and its value is a list with the index of each imputation for that column. These indices represent where data was originally missing but is now imputed. We can use these indices to find the location of imputations within a transformed dataset. The code below accesses the first 5 imputations for **x** and **y**. Because we used mean imputation, the imputation values are the same. In this case, the **record with index 5** had missing values for both **x** and **y**.\n\n\n\\`\\`\\`python\nprint_header(\"Showing the first 5 imputations for column x\")\ndata_imputed.loc[imputer.imputed_['x'], 'x'].head()\n\\`\\`\\`\n\n    Showing the first 5 imputations for column x\n    --------------------------------------------\n\n    5     7.577981\n    13    7.577981\n    24    7.577981\n    29    7.577981\n    30    7.577981\n    Name: x, dtype: float64\n\n\n\n\n\\`\\`\\`python\nprint_header(\"Showing the first 5 imputations for column y\")\ndata_imputed.loc[imputer.imputed_['y'], 'y'].head()\n\\`\\`\\`\n\n    Showing the first 5 imputations for column y\n    --------------------------------------------\n\n    5     3.747201\n    7     3.747201\n    8     3.747201\n    13    3.747201\n    18    3.747201\n    Name: y, dtype: float64\n\n\n\n#### 2.3. Make Imputation Flexible\nTo make Imputers powerful, we need to make them flexible. While Autoimpute Imputers set default values for their arguments, the Imputers' arguments give users full control of how to impute each column within a dataset. Let's see what arguments Imputers take. The code below prints each argument's name and its default value.\n\n\n\\`\\`\\`python\nprint_header(\"Printing arguments for the SingleImputer as well as their default values\")\nfor k,v in SingleImputer().get_params().items():\n    print(f\"Argument: {k}; Default: {v}\")\n\\`\\`\\`\n\n    Printing arguments for the SingleImputer as well as their default values\n    ------------------------------------------------------------------------\n    Argument: copy; Default: True\n    Argument: imp_kwgs; Default: None\n    Argument: predictors; Default: all\n    Argument: seed; Default: None\n    Argument: strategy; Default: default predictive\n    Argument: visit; Default: default\n\n\nBelow is a brief description of each argument. Part II of this series explains how to use these arguments to control imputation.  \n* **copy**: Whether or not to copy the dataset during the transform place. If False, imputations happen in place.  \n* **imp_kwgs**: Dictionary of arguments to fine-tune imputation on a specific column or for a specific imputation strategy.  \n* **predictors**: Which columns to use to predict imputations for a given column's imputation model.  \n* **seed**: Seed number makes imputations reproducible.  \n* **strategy**: The imputation strategy to use. Can specify for all columns or each column individually.  \n* **visit**: The order in which columns should be \"visited\" or imputed.  \n\n\nThis concludes Part I of this series. This tutorial is merely an introduction to the \\`Autoimpute\\` Imputers. We motivated the need for Autoimpute Imputers and introduced the package design at the highest level, but we barely scratched the surface for what Imputers can do. In the code segment above, we peeked at the arguments an \\`Imputer\\` takes. These arguments give the user full control over the imputation process and hold the power and flexibility behind the \\`Imputer\\` classes. Part II of this series walks through these arguments in depth, giving users examples of how the arguments tailor imputation to fit specific needs.\n\n\n`\n\nclass ImputerI extends Component {\n    render() {\n      return (\n        <div className=\"imputer-I\">\n            <ReactMarkdown source={header} escapeHtml={false} renderers={{code: CodeBlock}} />\n            <ReactMarkdown source={codePlot} escapeHtml={false} renderers={{code: CodeBlock}} />\n            <img alt=\"imputer-I-scatter\" src=\"https://kearnz.github.io/autoimpute-tutorials/img/imputer/imputer-I-scatter.png\"></img>\n            <ReactMarkdown source={partOne} escapeHtml={false} renderers={{code: CodeBlock}} />\n            <ReactMarkdown source={partTwoOne} escapeHtml={false} renderers={{code: CodeBlock}} />\n            <table border=\"1\" className=\"dataframe\">\n                <thead>\n                <tr>\n                    <th>label</th>\n                    <th>x</th>\n                    <th>y</th>\n                </tr>\n                </thead>\n                <tbody>\n                    <tr>\n                    <td><b>records missing</b></td>\n                    <td>285</td>\n                    <td>491</td>\n                    </tr>\n                </tbody>\n            </table>\n            <ReactMarkdown source={partTwoTwo} escapeHtml={false} renderers={{code: CodeBlock}} />\n            <table border=\"1\" className=\"dataframe\">\n            <thead>\n                <tr>\n                <th>label</th>\n                <th>x</th>\n                <th>y</th>\n                </tr>\n            </thead>\n            <tbody>\n                <tr>\n                <td><b>records missing</b></td>\n                <td>0</td>\n                <td>0</td>\n                </tr>\n            </tbody>\n            </table>\n            <ReactMarkdown source={partTwoThree} escapeHtml={false} renderers={{code: CodeBlock}} />\n            <table border=\"1\" className=\"dataframe\">\n                <thead>\n                    <tr>\n                    <th>x</th>\n                    <th>y</th>\n                    </tr>\n                </thead>\n                <tbody>\n                    <tr>\n                    <td>2.534781</td>\n                    <td>0.257901</td>\n                    </tr>\n                    <tr>\n                    <td>-0.118755</td>\n                    <td>-0.114591</td>\n                    </tr>\n                    <tr>\n                    <td>-1.184612</td>\n                    <td>0.018801</td>\n                    </tr>\n                    <tr>\n                    <td>1.442059</td>\n                    <td>0.047037</td>\n                    </tr>\n                    <tr>\n                    <td>0.109537</td>\n                    <td>0.229042</td>\n                    </tr>\n                    <tr>\n                    <td>NaN</td>\n                    <td>NaN</td>\n                    </tr>\n                    <tr>\n                    <td>-0.962892</td>\n                    <td>0.000090</td>\n                    </tr>\n                    <tr>\n                    <td>-0.028426</td>\n                    <td>NaN</td>\n                    </tr>\n                    <tr>\n                    <td>1.949358</td>\n                    <td>NaN</td>\n                    </tr>\n                    <tr>\n                    <td>-1.728996</td>\n                    <td>0.068058</td>\n                    </tr>\n                </tbody>\n            </table>\n            <ReactMarkdown source={partTwoFour} escapeHtml={false} renderers={{code: CodeBlock}} />\n            <table border=\"1\" className=\"dataframe\">\n                <thead>\n                    <tr>\n                    <th>x</th>\n                    <th>y</th>\n                    </tr>\n                </thead>\n                <tbody>\n                    <tr>\n                    <td>2.534781</td>\n                    <td>0.257901</td>\n                    </tr>\n                    <tr>\n                    <td>-0.118755</td>\n                    <td>-0.114591</td>\n                    </tr>\n                    <tr>\n                    <td>-1.184612</td>\n                    <td>0.018801</td>\n                    </tr>\n                    <tr>\n                    <td>1.442059</td>\n                    <td>0.047037</td>\n                    </tr>\n                    <tr>\n                    <td>0.109537</td>\n                    <td>0.229042</td>\n                    </tr>\n                    <tr>\n                    <td>7.577981</td>\n                    <td>3.747201</td>\n                    </tr>\n                    <tr>\n                    <td>-0.962892</td>\n                    <td>0.000090</td>\n                    </tr>\n                    <tr>\n                    <td>-0.028426</td>\n                    <td>3.747201</td>\n                    </tr>\n                    <tr>\n                    <td>1.949358</td>\n                    <td>3.747201</td>\n                    </tr>\n                    <tr>\n                    <td>-1.728996</td>\n                    <td>0.068058</td>\n                    </tr>\n                </tbody>\n            </table>\n            <ReactMarkdown source={partTwoFive} escapeHtml={false} renderers={{code: CodeBlock}} />\n        </div>\n        );\n    }\n  }\n\n  export default ImputerI;","import React, { Component } from \"react\";\nimport ReactMarkdown from \"react-markdown\";\nimport CodeBlock from \"./CodeBlock\";\n\nclass ImputerII extends Component {\n    render() {\n      return (\n        <h1>Imputer Mechanics II</h1>\n        );\n    }\n  }\n   \n  export default ImputerII;","import React, { Component } from \"react\";\nimport ReactMarkdown from \"react-markdown\";\nimport CodeBlock from \"./CodeBlock\";\n\nclass ImputerIII extends Component {\n    render() {\n      return (\n        <h1>Imputer Mechanics III</h1>\n        );\n    }\n  }\n   \n  export default ImputerIII;","import React, { Component } from \"react\";\nimport ReactMarkdown from \"react-markdown\";\nimport CodeBlock from \"./CodeBlock\";\n\n// HEADER TO START THE TUTORIAL\nconst inputHeader01 = `\n## An End-to-End Analysis of Missing Data using Autoimpute\n\n* This tutorial demonstrates how an analyst can utilize the \\`Autoimpute\\` package to handle missing data from exploration through supervised learning.  \n* It presents **two examples, side by side**. The process for each example is the same, but the underlying datasets (and their missingness) differ.  \n* The example on the left explores data with **MCAR** missingness, while the example on the right examines data with **MAR** missingness.  \n`\n\n/* START OF MCAR BELOW \n---------------------\n*/\n\nconst mcarHeader = `\n## MCAR\n---\n* 500 observations for two features, **predictor x** and **response y**  \n* Correlation between the variables is **0.7**\n* Predictor **x** is fully observed, while response **y** is missing **40%** of the observations\n* The underlying missingness mechanism is **MCAR**  \n* Imputation methods explored: **mean**, **least squares**, **PMM**    \n`\n\nconst mcarDataPrep = `\n### Imports and Data Preparation\n---\n\\`\\`\\`python\n'''Handling imports for analysis'''\n%matplotlib inline\n\n# general modules\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# autoimpute imports - utilities & visuals\nfrom autoimpute.utils import md_pattern, proportions\nfrom autoimpute.visuals import plot_md_locations, plot_md_percent\nfrom autoimpute.visuals import plot_imp_dists, plot_imp_boxplots\nfrom autoimpute.visuals import plot_imp_swarm, plot_imp_strip\nfrom autoimpute.visuals import plot_imp_scatter\n\n# autoimpute imports - imputations & analysis\nfrom autoimpute.imputations import MultipleImputer\nfrom autoimpute.analysis import MiLinearRegression\n\n# reading the full dataset and mcar dataset\nfull = pd.read_csv(\"full.csv\")\nmcar = pd.read_csv(\"mcar.csv\")\n\\`\\`\\`\n`\n\nconst mcarPercent = `\n### Percent Missing by Feature\n---\n\\`\\`\\`python\n'''MCAR percent plot'''\nplot_md_percent(mcar)\n\\`\\`\\`\n`\n\nconst mcarLocation = `\n### Location of Missingness by Feature\n---\n\\`\\`\\`python\n'''MCAR location plot'''\nplot_md_locations(mcar)\n\\`\\`\\`\n`\n\nconst mcarMean = `\n### Mean Imputation\n---\n\\`\\`\\`python\n'''MCAR mean imputation'''\n\n# create the mean imputer\nmi_mean_mcar = MultipleImputer(\n    strategy=\"mean\", n=5, return_list=True, seed=101\n)\n\n# print the mean imputer to console\nprint(mi_mean_mcar)\n\n# perform mean imputation procedure\nimp_mean_mcar = mi_mean_mcar.fit_transform(mcar)\n\\`\\`\\`\n`\n\nconst mcarMeanDistBox = `\n### Distribution Plots after Mean Imputation\n---\n\\`\\`\\`python\n'''MCAR distribution plots after mean imputation'''\n\n# distribution plot for mean imputation\nplot_imp_dists(\n    d=imp_mean_mcar,\n    mi=mi_mean_mcar, \n    col=\"y\",\n    title=\"Distributions after Mean Imputation: MCAR\",\n    separate_observed=False,\n    hist_observed=True,\n    hist_imputed=False\n)\n\n# box plot for mean imputation\nplot_imp_boxplots(\n    d=imp_mean_mcar,\n    mi=mi_mean_mcar,\n    col=\"y\",\n    title=\"Boxplots after Mean Imputation: MCAR\"\n)\n\n# strip plot for mean imputation\nplot_imp_strip(\n    d=imp_mean_mcar,\n    mi=mi_mean_mcar,\n    col=\"y\",\n    title=\"Imputed vs Observed Dists after Mean Imputation: MCAR\"\n)\n\\`\\`\\`\n`\nconst mcarLs = `\n### Distribution Plots after Least Squares Imputation\n---\n\\`\\`\\`python\n'''MCAR distribution plots after least squares imputation'''\n\n# create the least squares imputer\nmi_ls_mcar = MultipleImputer(\n    strategy=\"least squares\", n=5, return_list=True, seed=101\n)\n\n# perform least squares imputation procedure\nimp_ls_mcar = mi_ls_mcar.fit_transform(mcar)\n\n# distribution plot for least squares imputation\nplot_imp_dists(\n    d=imp_ls_mcar,\n    mi=mi_ls_mcar, \n    col=\"y\",\n    title=\"Distributions after Least Squares Imputation: MCAR\",\n    separate_observed=False,\n    hist_observed=True,\n    hist_imputed=False\n)\n\n# box plot for least squares imputation\nplot_imp_boxplots(\n    d=imp_ls_mcar,\n    mi=mi_ls_mcar,\n    col=\"y\",\n    title=\"Boxplots after Least Squares Imputation: MCAR\"\n)\n\n# strip plot for least squares imputation\nplot_imp_strip(\n    d=imp_ls_mcar,\n    mi=mi_ls_mcar,\n    col=\"y\",\n    title=\"Imputed vs Observed Dists after Least Squares Imputation: MCAR\"\n)\n\\`\\`\\`\n`\n\nconst mcarPmm = `\n### Distribution Plots after PMM Imputation\n---\n\\`\\`\\`python\n'''MCAR distribution plots after PMM imputation'''\n\n# create the PMM imputer\nmi_pmm_mcar = MultipleImputer(\n    strategy=\"pmm\", n=5, return_list=True, seed=101\n)\n\n# perform PMM imputation procedure\nimp_pmm_mcar = mi_pmm_mcar.fit_transform(mcar)\n\n# distribution plot for PMM imputation\nplot_imp_dists(\n    d=imp_pmm_mcar,\n    mi=mi_pmm_mcar, \n    col=\"y\",\n    title=\"Distributions after PMM Imputation: MCAR\",\n    separate_observed=False,\n    hist_observed=True,\n    hist_imputed=False\n)\n\n# box plot for PMM imputation\nplot_imp_boxplots(\n    d=imp_pmm_mcar,\n    mi=mi_pmm_mcar,\n    col=\"y\",\n    title=\"Boxplots after PMM Imputation: MCAR\"\n)\n\n# swarm plot for PMM imputation\nplot_imp_swarm(\n    d=imp_pmm_mcar,\n    mi=mi_pmm_mcar,\n    col=\"y\",\n    title=\"Imputed vs Observed Dists after PMM Imputation: MCAR\"\n)\n\\`\\`\\`\n`\n\nconst mcarRegression = `\n### Linear Regression on Multiply Imputed Data\n---\n\\`\\`\\`python\n'''Regression after Multiple Imputation on MCAR'''\n\n# NOTE: Full & Listwise delete code not included but appear in output\n\n# create the regression using custom imputers\nlm_mean_mcar = MiLinearRegression(mi=mi_mean_mcar)\nlm_ls_mcar = MiLinearRegression(mi=mi_ls_mcar)\nlm_pmm_mcar = MiLinearRegression(mi=mi_pmm_mcar)\nmodels_mcar = [lm_mean_mcar, lm_ls_mcar, lm_pmm_mcar]\n\n# a bit of manipulation to create one dataframe\nget_coeff = lambda lm_, x: lm_.summary().loc[\"x\"].to_frame()\nres_mcar = pd.concat([get_coeff(lm, \"x\") for lm in models_mcar], axis=1)\nres_mcar.columns = [\"mean\", \"least squares\", \"pmm\"]\nres_mcar = res_mcar.T[[\"coefs\", \"std\", \"vw\", \"vb\", \"vt\"]]\n\n# show the results\nres_mcar\n\\`\\`\\`\n`\n\nconst mcarScatter = `\n### Scatterplots after Imputation Methods\n---\n\\`\\`\\`python\n'''Visualizing effect of imputation on regression for scatter'''\n\n# scatterplot for mean\nplot_imp_scatter(\n    d=mcar, x=\"x\", y=\"y\", strategy=\"mean\", color=\"y\",\n    title=\"Scatter after Mean Imputation: MCAR\"\n)\n\n# scatterplot for least squares\nplot_imp_scatter(\n    d=mcar, x=\"x\", y=\"y\", strategy=\"least squares\", color=\"y\",\n    title=\"Scatter after Least Squares Imputation: MCAR\"\n)\n\n# scatterplot for pmm\nplot_imp_scatter(\n    d=mcar, x=\"x\", y=\"y\", strategy=\"pmm\", color=\"y\",\n    title=\"Scatter after PMM Imputation: MCAR\"\n)\n\n\\`\\`\\`\n`\n\n\n/* START OF MAR BELOW \n---------------------\n*/\n\nconst marHeader = `\n## MAR\n---\n* 500 observations for two features, **predictor x** and **response y**  \n* Correlation between the variables is **0.7**\n* Predictor **x** is missing **40%** of the observations, while response **y** is fully observed  \n* The underlying missingness mechanism is **MAR**  \n* Imputation methods explored: **mean**, **least squares**, **PMM**  \n`\n\nconst marDataPrep = `\n### Imports and Data Preparation\n---\n\\`\\`\\`python\n'''Handling imports for analysis'''\n%matplotlib inline\n\n# general modules\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# autoimpute imports - utilities & visuals\nfrom autoimpute.utils import md_pattern, proportions\nfrom autoimpute.visuals import plot_md_locations, plot_md_percent\nfrom autoimpute.visuals import plot_imp_dists, plot_imp_boxplots\nfrom autoimpute.visuals import plot_imp_swarm, plot_imp_strip\nfrom autoimpute.visuals import plot_imp_scatter\n\n# autoimpute imports - imputations & analysis\nfrom autoimpute.imputations import MultipleImputer\nfrom autoimpute.analysis import MiLinearRegression\n\n# reading the full dataset and mar dataset\nfull = pd.read_csv(\"full.csv\")\nmar = pd.read_csv(\"mar.csv\")\n\\`\\`\\`\n`\n\nconst marPercent = `\n### Percent Missing by Feature\n---\n\\`\\`\\`python\n'''MAR percent plot'''\nplot_md_percent(mar)\n\\`\\`\\`\n`\n\nconst marLocation = `\n### Location of Missingness by Feature\n---\n\\`\\`\\`python\n'''MAR location plot'''\nplot_md_locations(mar)\n\\`\\`\\`\n`\n\nconst marMean = `\n### Mean Imputation\n---\n\\`\\`\\`python\n'''MAR mean imputation'''\n\n# create the mean imputer\nmi_mean_mar = MultipleImputer(\n    strategy=\"mean\", n=5, return_list=True, seed=101\n)\n\n# print the mean imputer to console\nprint(mi_mean_mar)\n\n# perform mean imputation procedure\nimp_mean_mar = mi_mean_mar.fit_transform(mar)\n\\`\\`\\`\n`\n\nconst marMeanDistBox = `\n### Distribution Plots after Mean Imputation\n---\n\\`\\`\\`python\n'''MAR distribution plots after mean imputation'''\n\n# distribution plot for mean imputation\nplot_imp_dists(\n    d=imp_mean_mar,\n    mi=mi_mean_mar, \n    col=\"x\",\n    title=\"Distributions after Mean Imputation: MAR\",\n    separate_observed=False,\n    hist_observed=True,\n    hist_imputed=False\n)\n\n# box plot for mean imputation\nplot_imp_boxplots(\n    d=imp_mean_mar,\n    mi=mi_mean_mar,\n    col=\"x\",\n    title=\"Boxplots after Mean Imputation: MAR\"\n)\n\n# strip plot for mean imputation\nplot_imp_strip(\n    d=imp_mean_mar,\n    mi=mi_mean_mar,\n    col=\"x\",\n    title=\"Imputed vs Observed Dists after Mean Imputation: MAR\"\n)\n\\`\\`\\`\n`\n\nconst marLs = `\n### Distribution Plots after Least Squares Imputation\n---\n\\`\\`\\`python\n'''MAR distribution plots after least squares imputation'''\n\n# create the least squares imputer\nmi_ls_mar = MultipleImputer(\n    strategy=\"least squares\", n=5, return_list=True, seed=101\n)\n\n# perform least squares imputation procedure\nimp_ls_mar = mi_ls_mar.fit_transform(mar)\n\n# distribution plot for least squares imputation\nplot_imp_dists(\n    d=imp_ls_mar,\n    mi=mi_ls_mar, \n    col=\"x\",\n    title=\"Distributions after Least Squares Imputation: MAR\",\n    separate_observed=False,\n    hist_observed=True,\n    hist_imputed=False\n)\n\n# box plot for least squares imputation\nplot_imp_boxplots(\n    d=imp_ls_mar,\n    mi=mi_ls_mar,\n    col=\"x\",\n    title=\"Boxplots after Least Squares Imputation: MAR\"\n)\n\n# strip plot for least squares imputation\nplot_imp_strip(\n    d=imp_ls_mar,\n    mi=mi_ls_mar,\n    col=\"x\",\n    title=\"Imputed vs Observed Dists after Least Squares Imputation: MAR\"\n)\n\\`\\`\\`\n`\n\nconst marPmm = `\n### Distribution Plots after PMM Imputation\n---\n\\`\\`\\`python\n'''MAR distribution plots after PMM imputation'''\n\n# create the PMM imputer\nmi_pmm_mar = MultipleImputer(\n    strategy=\"pmm\", n=5, return_list=True, seed=101\n)\n\n# perform PMM imputation procedure\nimp_pmm_mar = mi_pmm_mar.fit_transform(mar)\n\n# distribution plot for PMM imputation\nplot_imp_dists(\n    d=imp_pmm_mar,\n    mi=mi_pmm_mar, \n    col=\"x\",\n    title=\"Distributions after PMM Imputation: MAR\",\n    separate_observed=False,\n    hist_observed=True,\n    hist_imputed=False\n)\n\n# box plot for PMM imputation\nplot_imp_boxplots(\n    d=imp_pmm_mar,\n    mi=mi_pmm_mar,\n    col=\"x\",\n    title=\"Boxplots after PMM Imputation: MAR\"\n)\n\n# swarm plot for PMM imputation\nplot_imp_swarm(\n    d=imp_pmm_mar,\n    mi=mi_pmm_mar,\n    col=\"x\",\n    title=\"Imputed vs Observed Dists after PMM Imputation: MAR\"\n)\n\\`\\`\\`\n`\n\nconst marRegression = `\n### Linear Regression on Multiply Imputed Data\n---\n\\`\\`\\`python\n'''Regression after Multiple Imputation on MAR'''\n\n# NOTE: Full & Listwise delete code not included but appear in output\n\n# create the regression using custom imputers\nlm_mean_mar = MiLinearRegression(mi=mi_mean_mar)\nlm_ls_mar = MiLinearRegression(mi=mi_ls_mar)\nlm_pmm_mar = MiLinearRegression(mi=mi_pmm_mar)\nmodels_mar = [lm_mean_mar, lm_ls_mar, lm_pmm_mar]\n\n# a bit of manipulation to create one dataframe\nget_coeff = lambda lm_, x: lm_.summary().loc[\"x\"].to_frame()\nres_mar = pd.concat([get_coeff(lm, \"x\") for lm in models_mar], axis=1)\nres_mar.columns = [\"mean\", \"least squares\", \"pmm\"]\nres_mar = res_mar.T[[\"coefs\", \"std\", \"vw\", \"vb\", \"vt\"]]\n\n# show the results\nres_mar\n\\`\\`\\`\n`\n\nconst marScatter = `\n### Scatterplots after Imputation Methods\n---\n\\`\\`\\`python\n'''Visualizing effect of imputation on regression for scatter'''\n\n# scatterplot for mean\nplot_imp_scatter(\n    d=mar, x=\"x\", y=\"y\", strategy=\"mean\", color=\"x\",\n    title=\"Scatter after Mean Imputation: MAR\"\n)\n\n# scatterplot for least squares\nplot_imp_scatter(\n    d=mar, x=\"x\", y=\"y\", strategy=\"least squares\", color=\"x\",\n    title=\"Scatter after Least Squares Imputation: MAR\"\n)\n\n# scatterplot for pmm\nplot_imp_scatter(\n    d=mar, x=\"x\", y=\"y\", strategy=\"pmm\", color=\"x\",\n    title=\"Scatter after PMM Imputation: MAR\"\n)\n\n\\`\\`\\`\n`\n\n\nclass EndToEnd extends Component {\n    render() {\n      return (\n        <div className=\"end-to-end\">\n          <div className=\"ete-header-01\">\n            <ReactMarkdown source={inputHeader01} escapeHtml={false} renderers={{code: CodeBlock}} />\n          </div>\n          <div className=\"ete-mcar\">\n            <ReactMarkdown source={mcarHeader} escapeHtml={false} renderers={{code: CodeBlock}} />\n            <ReactMarkdown source={mcarDataPrep} escapeHtml={false} renderers={{code: CodeBlock}} />\n            <ReactMarkdown source={mcarPercent} escapeHtml={false} renderers={{code: CodeBlock}} />\n            <img alt=\"mcarPercent\" className=\"ete-percent\" src=\"https://kearnz.github.io/autoimpute-tutorials/img/ete/ete-mcar-plot-md-percent.png\"></img>\n            <ReactMarkdown source={mcarLocation} escapeHtml={false} renderers={{code: CodeBlock}} />\n            <img alt=\"mcarLocation\" className=\"ete-locations\" src=\"https://kearnz.github.io/autoimpute-tutorials/img/ete/ete-mcar-plot-md-locations.png\"></img>\n            <ReactMarkdown source={mcarMean} escapeHtml={false} renderers={{code: CodeBlock}} />\n            <img alt=\"mcarMeanImputer\" className=\"ete-mean-imputer\" src=\"https://kearnz.github.io/autoimpute-tutorials/img/ete/ete-mean-imputer.png\"></img>\n            <ReactMarkdown source={mcarMeanDistBox} escapeHtml={false} renderers={{code: CodeBlock}} />\n            <img alt=\"mcarMeanImputerDist\" className=\"ete-dist\" src=\"https://kearnz.github.io/autoimpute-tutorials/img/ete/ete-mcar-mean-dist.png\"></img>\n            <img alt=\"mcarMeanImputerBox\" className=\"ete-box\" src=\"https://kearnz.github.io/autoimpute-tutorials/img/ete/ete-mcar-mean-box.png\"></img>\n            <img alt=\"mcarMeanImputerStrip\" className=\"ete-strip\" src=\"https://kearnz.github.io/autoimpute-tutorials/img/ete/ete-mcar-mean-strip.png\"></img>\n            <ReactMarkdown source={mcarLs} escapeHtml={false} renderers={{code: CodeBlock}} />\n            <img alt=\"mcarLsImputerDist\" className=\"ete-dist\" src=\"https://kearnz.github.io/autoimpute-tutorials/img/ete/ete-mcar-ls-dist.png\"></img>\n            <img alt=\"mcarLsImputerBox\" className=\"ete-box\" src=\"https://kearnz.github.io/autoimpute-tutorials/img/ete/ete-mcar-ls-box.png\"></img>\n            <img alt=\"mcarLsImputerStrip\" className=\"ete-strip\" src=\"https://kearnz.github.io/autoimpute-tutorials/img/ete/ete-mcar-ls-strip.png\"></img>\n            <ReactMarkdown source={mcarPmm} escapeHtml={false} renderers={{code: CodeBlock}} />\n            <img alt=\"mcarPmmImputerDist\" className=\"ete-dist\" src=\"https://kearnz.github.io/autoimpute-tutorials/img/ete/ete-mcar-pmm-dist.png\"></img>\n            <img alt=\"mcarPmmImputerBox\" className=\"ete-box\" src=\"https://kearnz.github.io/autoimpute-tutorials/img/ete/ete-mcar-pmm-box.png\"></img>\n            <img alt=\"mcarPmmImputerSwarm\" className=\"ete-swarm\" src=\"https://kearnz.github.io/autoimpute-tutorials/img/ete/ete-mcar-pmm-swarm.png\"></img>\n            <ReactMarkdown source={mcarRegression} escapeHtml={false} renderers={{code: CodeBlock}} />\n            <table border=\"1\" className=\"dataframe\">  \n                <thead>    \n                    <tr>      \n                        <th>method</th>      \n                        <th>coefs</th>      \n                        <th>std</th>      \n                        <th>vw</th>     \n                        <th>vb</th>      \n                        <th>vt</th>    \n                    </tr> \n                </thead>\n                <tbody>    \n                    <tr>      \n                        <td><b>full</b></td>      \n                        <td>0.70000</td>      \n                        <td>0.03200</td>      \n                        <td>0.00102</td>      \n                        <td>0.00000</td>      \n                        <td>0.00102</td>    \n                    </tr>    \n                    <tr>      \n                        <td><b>listwise delete</b></td>      \n                        <td>0.73915</td>      \n                        <td>0.04682</td>      \n                        <td>0.00219</td>      \n                        <td>0.00000</td>      \n                        <td>0.00219</td>    \n                    </tr>    \n                    <tr>      \n                        <td><b>mean</b></td>      \n                        <td>0.39330</td>      \n                        <td>0.03056</td>      \n                        <td>0.00093</td>      \n                        <td>0.00000</td>      \n                        <td>0.00093</td>    \n                    </tr>    \n                    <tr>      \n                        <td><b>least squares</b></td>      \n                        <td>0.73915</td>      \n                        <td>0.02570</td>      \n                        <td>0.00066</td>      \n                        <td>0.00000</td>      \n                        <td>0.00066</td>    \n                        </tr>    \n                    <tr>      \n                        <td><b>pmm</b></td>      \n                        <td>0.67692</td>      \n                        <td>0.05404</td>      \n                        <td>0.00128</td>      \n                        <td>0.00136</td>      \n                        <td>0.00292</td>    \n                    </tr>  \n                    </tbody>\n                </table>\n            <ReactMarkdown source={mcarScatter} escapeHtml={false} renderers={{code: CodeBlock}} /> \n            <img alt=\"mcarMeanScatter\" className=\"ete-scatter\" src=\"https://kearnz.github.io/autoimpute-tutorials/img/ete/ete-mcar-mean-scatter.png\"></img>\n            <img alt=\"mcarLsScatter\" className=\"ete-scatter\" src=\"https://kearnz.github.io/autoimpute-tutorials/img/ete/ete-mcar-ls-scatter.png\"></img>\n            <img alt=\"mcarPmmScatter\" className=\"ete-scatter\" src=\"https://kearnz.github.io/autoimpute-tutorials/img/ete/ete-mcar-pmm-scatter.png\"></img>\n                       \n          </div>\n          <div className=\"ete-mar\">\n            <ReactMarkdown source={marHeader} escapeHtml={false} renderers={{code: CodeBlock}} />\n            <ReactMarkdown source={marDataPrep} escapeHtml={false} renderers={{code: CodeBlock}} />\n            <ReactMarkdown source={marPercent} escapeHtml={false} renderers={{code: CodeBlock}} />\n            <img alt=\"marPercent\" className=\"ete-percent\"  src=\"https://kearnz.github.io/autoimpute-tutorials/img/ete/ete-mar-plot-md-percent.png\"></img>\n            <ReactMarkdown source={marLocation} escapeHtml={false} renderers={{code: CodeBlock}} />\n            <img alt=\"marLocation\" className=\"ete-locations\" src=\"https://kearnz.github.io/autoimpute-tutorials/img/ete/ete-mar-plot-md-locations.png\"></img>\n            <ReactMarkdown source={marMean} escapeHtml={false} renderers={{code: CodeBlock}} />\n            <img alt=\"marMeanImputer\" className=\"ete-mean-imputer\" src=\"https://kearnz.github.io/autoimpute-tutorials/img/ete/ete-mean-imputer.png\"></img>\n            <ReactMarkdown source={marMeanDistBox} escapeHtml={false} renderers={{code: CodeBlock}} />\n            <img alt=\"marMeanImputerDist\" className=\"ete-dist\" src=\"https://kearnz.github.io/autoimpute-tutorials/img/ete/ete-mar-mean-dist.png\"></img>\n            <img alt=\"marMeanImputerBox\" className=\"ete-box\" src=\"https://kearnz.github.io/autoimpute-tutorials/img/ete/ete-mar-mean-box.png\"></img>\n            <img alt=\"marMeanImputerStrip\" className=\"ete-strip\" src=\"https://kearnz.github.io/autoimpute-tutorials/img/ete/ete-mar-mean-strip.png\"></img>\n            <ReactMarkdown source={marLs} escapeHtml={false} renderers={{code: CodeBlock}} />\n            <img alt=\"marLsImputerDist\" className=\"ete-dist\" src=\"https://kearnz.github.io/autoimpute-tutorials/img/ete/ete-mar-ls-dist.png\"></img>\n            <img alt=\"marLsImputerBox\" className=\"ete-box\" src=\"https://kearnz.github.io/autoimpute-tutorials/img/ete/ete-mar-ls-box.png\"></img>\n            <img alt=\"marLsImputerStrip\" className=\"ete-strip\" src=\"https://kearnz.github.io/autoimpute-tutorials/img/ete/ete-mar-ls-strip.png\"></img>\n            <ReactMarkdown source={marPmm} escapeHtml={false} renderers={{code: CodeBlock}} />\n            <img alt=\"marPmmImputerDist\" className=\"ete-dist\" src=\"https://kearnz.github.io/autoimpute-tutorials/img/ete/ete-mar-pmm-dist.png\"></img>\n            <img alt=\"marPmmImputerBox\" className=\"ete-box\" src=\"https://kearnz.github.io/autoimpute-tutorials/img/ete/ete-mar-pmm-box.png\"></img>\n            <img alt=\"marPmmImputerSwarm\" className=\"ete-swarm\" src=\"https://kearnz.github.io/autoimpute-tutorials/img/ete/ete-mar-pmm-swarm.png\"></img>\n            <ReactMarkdown source={marRegression} escapeHtml={false} renderers={{code: CodeBlock}} />\n            <table border=\"1\" className=\"dataframe\">\n                <thead>\n                    <tr>\n                        <th>method</th>\n                        <th>coefs</th>\n                        <th>std</th>\n                        <th>vw</th>\n                        <th>vb</th>      \n                        <th>vt</th>    \n                    </tr>\n                </thead>\n                <tbody>\n                    <tr>\n                        <td><b>full</b></td>      \n                        <td>0.70000</td>      \n                        <td>0.03200</td>      \n                        <td>0.00102</td>      \n                        <td>0.00000</td>      \n                        <td>0.00102</td>    \n                    </tr>    \n                    <tr>      \n                        <td><b>listwise delete</b></td>      \n                        <td>0.66180</td>      \n                        <td>0.03865</td>      \n                        <td>0.00149</td>      \n                        <td>0.00000</td>      \n                        <td>0.00149</td>    \n                    </tr>    \n                    <tr>      \n                        <td><b>mean</b></td>      \n                        <td>0.66180</td>      \n                        <td>0.04896</td>      \n                        <td>0.00240</td>      \n                        <td>0.00000</td>      \n                        <td>0.00240</td>    \n                    </tr>    \n                    <tr>      \n                        <td><b>least squares</b></td>      \n                        <td>0.86053</td>      \n                        <td>0.02889</td>      \n                        <td>0.00083</td>      \n                        <td>0.00000</td>      \n                        <td>0.00083</td>    \n                    </tr>    \n                    <tr>      \n                        <td><b>pmm</b></td>      \n                        <td>0.69690</td>     \n                        <td>0.03707</td>      \n                        <td>0.00096</td>      \n                        <td>0.00034</td>      \n                        <td>0.00137</td>    \n                    </tr>  \n                </tbody>\n            </table>\n            <ReactMarkdown source={marScatter} escapeHtml={false} renderers={{code: CodeBlock}} />\n            <img alt=\"marMeanScatter\" className=\"ete-scatter\" src=\"https://kearnz.github.io/autoimpute-tutorials/img/ete/ete-mar-mean-scatter.png\"></img>\n            <img alt=\"marLsScatter\" className=\"ete-scatter\" src=\"https://kearnz.github.io/autoimpute-tutorials/img/ete/ete-mar-ls-scatter.png\"></img>\n            <img alt=\"marPmmScatter\" className=\"ete-scatter\" src=\"https://kearnz.github.io/autoimpute-tutorials/img/ete/ete-mar-pmm-scatter.png\"></img>\n\n          </div>\n        </div>\n      );\n    }\n  }\n\nexport default EndToEnd;","import React, { Component } from 'react';\nimport $ from 'jquery';\nimport Contact from \"./Contact\";\nimport Home from \"./Home\";\nimport Comparing from \"./Comparing\";\nimport ImputerI from \"./ImputerI\";\nimport ImputerII from \"./ImputerII\";\nimport ImputerIII from \"./ImputerIII\";\nimport EndToEnd from \"./EndToEnd\";\n\n\nconst NavItem = props => {\n  const pageURI = window.location.pathname+window.location.search\n  const liClassName = (props.path === pageURI) ? \"nav-item active\" : \"nav-item\";\n  const aClassName = props.disabled ? \"nav-link disabled\" : \"nav-link\"\n  return (\n    <li className={liClassName}>\n      <a onClick={() => props.onClick()} href={props.path} className={aClassName}>\n        {props.name}\n        {(props.path === pageURI) ? (<span className=\"sr-only\">(current)</span>) : ''}\n      </a>\n    </li>\n  );\n}\n\nclass NavDropdown extends Component {\n  constructor(props) {\n    super(props);\n    this.state = {\n      isToggleOn: false\n    };\n  }\n  showDropdown(e) {\n    e.preventDefault();\n    this.setState(prevState => ({\n      isToggleOn: !prevState.isToggleOn\n    }));\n  }\n  render() {\n    const classDropdownMenu = 'dropdown-menu' + (this.state.isToggleOn ? ' show' : '')\n    return (\n      <li className=\"nav-item dropdown\">\n        <a className=\"nav-link dropdown-toggle\" id=\"navbarDropdown\" role=\"button\" data-toggle=\"dropdown\"\n          aria-haspopup=\"true\" aria-expanded=\"false\"\n          onClick={(e) => {this.showDropdown(e)}}>\n          {this.props.name}\n        </a>\n        <div className={classDropdownMenu} aria-labelledby=\"navbarDropdown\">\n          {this.props.children}\n        </div>\n      </li>\n    )\n  }\n}\n\n\nclass Navigation extends React.Component {\n  constructor(props) {\n        // Required step: always call the parent class' constructor\n        super(props);\n    \n        // Set the state directly. Use props if necessary.\n        this.state = {\n          activeKey: 1,\n          df: \"/autoimpute-tutorials/\"\n        }\n\n        //this.handleClick = this.handleClick.bind(this);\n  }\n  handleClick(key) {\n    //event.preventDefault();\n    this.setState({activeKey: key});\n    \n    // NOT A GOOD SOLUTION - temporary hack to remove dropdown\n    // but requires a double click on tutorial button next time\n    // because state not altered, class just changed to trigger event\n    // should not be using jquery for this moving forward\n    if($('.dropdown-menu').hasClass('show')){\n      $( \".dropdown-menu\" ).trigger( \"click\" );\n        $('.dropdown-menu').removeClass('show');\n    }\n  }\n  render() {\n    return (\n     <div className=\"main-page\">\n      <nav className=\"navbar navbar-expand-lg\">\n        <a className=\"navbar-brand\" href={this.state.df}>Autoimpute</a>\n        <div className=\"collapse navbar-collapse\" id=\"navbarSupportedContent\">\n          <ul className=\"navbar-nav mr-auto\">\n            <NavItem name=\"Home\" onClick={this.handleClick.bind(this, 1)} />\n            <NavItem name=\"Contact\" onClick={this.handleClick.bind(this, 2)} />\n            <NavDropdown name=\"Tutorials\">\n                <a className=\"dropdown-item\" href={this.props.path} onClick={this.handleClick.bind(this, 3.1)}>Exploring Missingness</a>\n                <a className=\"dropdown-item\" href={this.props.path} onClick={this.handleClick.bind(this, 3.2)}>Imputers: Part I</a>\n                <a className=\"dropdown-item\" href={this.props.path} onClick={this.handleClick.bind(this, 3.3)}>Imputers: Part II</a>\n                <a className=\"dropdown-item\" href={this.state.path} onClick={this.handleClick.bind(this, 3.4)}>Imputers: Part III</a>\n                <a className=\"dropdown-item\" href={this.state.path} onClick={this.handleClick.bind(this, 3.5)}>Comparing Imputation Methods</a>\n                <a className=\"dropdown-item\" href={this.state.path} onClick={this.handleClick.bind(this, 3.6)}>End-to-End Analysis</a>\n            </NavDropdown>\n          </ul>\n        </div>\n       </nav>\n       <div className=\"content\">\n         {this.state.activeKey === 1 ? <Home/> : null}\n         {this.state.activeKey === 2 ? <Contact/> : null}\n         {this.state.activeKey === 3.1 ? \"Coming Soon!\" : null}\n         {this.state.activeKey === 3.2 ? <ImputerI/> : null}\n         {this.state.activeKey === 3.3 ? <ImputerII/> : null}\n         {this.state.activeKey === 3.4 ? <ImputerIII/> : null}\n         {this.state.activeKey === 3.5 ? <Comparing/> : null}\n         {this.state.activeKey === 3.6 ? <EndToEnd/> : null}\n       </div>\n      </div>\n      \n    )\n  }\n}\n\nexport default Navigation;","import React, {Component} from 'react';\nimport './App.css';\nimport Navigation from './components/Navigation';\n\nclass App extends Component {\n  render () {\n    return (\n      <div>\n        <Navigation />\n      </div>\n    );\n  }\n}\n\nexport default App;\n","// This optional code is used to register a service worker.\n// register() is not called by default.\n\n// This lets the app load faster on subsequent visits in production, and gives\n// it offline capabilities. However, it also means that developers (and users)\n// will only see deployed updates on subsequent visits to a page, after all the\n// existing tabs open on the page have been closed, since previously cached\n// resources are updated in the background.\n\n// To learn more about the benefits of this model and instructions on how to\n// opt-in, read https://bit.ly/CRA-PWA\n\nconst isLocalhost = Boolean(\n  window.location.hostname === 'localhost' ||\n    // [::1] is the IPv6 localhost address.\n    window.location.hostname === '[::1]' ||\n    // 127.0.0.1/8 is considered localhost for IPv4.\n    window.location.hostname.match(\n      /^127(?:\\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}$/\n    )\n);\n\nexport function register(config) {\n  if (process.env.NODE_ENV === 'production' && 'serviceWorker' in navigator) {\n    // The URL constructor is available in all browsers that support SW.\n    const publicUrl = new URL(process.env.PUBLIC_URL, window.location.href);\n    if (publicUrl.origin !== window.location.origin) {\n      // Our service worker won't work if PUBLIC_URL is on a different origin\n      // from what our page is served on. This might happen if a CDN is used to\n      // serve assets; see https://github.com/facebook/create-react-app/issues/2374\n      return;\n    }\n\n    window.addEventListener('load', () => {\n      const swUrl = `${process.env.PUBLIC_URL}/service-worker.js`;\n\n      if (isLocalhost) {\n        // This is running on localhost. Let's check if a service worker still exists or not.\n        checkValidServiceWorker(swUrl, config);\n\n        // Add some additional logging to localhost, pointing developers to the\n        // service worker/PWA documentation.\n        navigator.serviceWorker.ready.then(() => {\n          console.log(\n            'This web app is being served cache-first by a service ' +\n              'worker. To learn more, visit https://bit.ly/CRA-PWA'\n          );\n        });\n      } else {\n        // Is not localhost. Just register service worker\n        registerValidSW(swUrl, config);\n      }\n    });\n  }\n}\n\nfunction registerValidSW(swUrl, config) {\n  navigator.serviceWorker\n    .register(swUrl)\n    .then(registration => {\n      registration.onupdatefound = () => {\n        const installingWorker = registration.installing;\n        if (installingWorker == null) {\n          return;\n        }\n        installingWorker.onstatechange = () => {\n          if (installingWorker.state === 'installed') {\n            if (navigator.serviceWorker.controller) {\n              // At this point, the updated precached content has been fetched,\n              // but the previous service worker will still serve the older\n              // content until all client tabs are closed.\n              console.log(\n                'New content is available and will be used when all ' +\n                  'tabs for this page are closed. See https://bit.ly/CRA-PWA.'\n              );\n\n              // Execute callback\n              if (config && config.onUpdate) {\n                config.onUpdate(registration);\n              }\n            } else {\n              // At this point, everything has been precached.\n              // It's the perfect time to display a\n              // \"Content is cached for offline use.\" message.\n              console.log('Content is cached for offline use.');\n\n              // Execute callback\n              if (config && config.onSuccess) {\n                config.onSuccess(registration);\n              }\n            }\n          }\n        };\n      };\n    })\n    .catch(error => {\n      console.error('Error during service worker registration:', error);\n    });\n}\n\nfunction checkValidServiceWorker(swUrl, config) {\n  // Check if the service worker can be found. If it can't reload the page.\n  fetch(swUrl)\n    .then(response => {\n      // Ensure service worker exists, and that we really are getting a JS file.\n      const contentType = response.headers.get('content-type');\n      if (\n        response.status === 404 ||\n        (contentType != null && contentType.indexOf('javascript') === -1)\n      ) {\n        // No service worker found. Probably a different app. Reload the page.\n        navigator.serviceWorker.ready.then(registration => {\n          registration.unregister().then(() => {\n            window.location.reload();\n          });\n        });\n      } else {\n        // Service worker found. Proceed as normal.\n        registerValidSW(swUrl, config);\n      }\n    })\n    .catch(() => {\n      console.log(\n        'No internet connection found. App is running in offline mode.'\n      );\n    });\n}\n\nexport function unregister() {\n  if ('serviceWorker' in navigator) {\n    navigator.serviceWorker.ready.then(registration => {\n      registration.unregister();\n    });\n  }\n}\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\nimport * as serviceWorker from './serviceWorker';\nimport '../node_modules/bootstrap/dist/css/bootstrap.min.css';\n\nReactDOM.render(<App />, document.getElementById('root'));\n\n// If you want your app to work offline and load faster, you can change\n// unregister() to register() below. Note this comes with some pitfalls.\n// Learn more about service workers: https://bit.ly/CRA-PWA\nserviceWorker.unregister();\n"],"sourceRoot":""}